{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-03T13:32:44.269927Z","iopub.status.busy":"2024-06-03T13:32:44.269512Z","iopub.status.idle":"2024-06-03T13:32:49.332686Z","shell.execute_reply":"2024-06-03T13:32:49.331554Z","shell.execute_reply.started":"2024-06-03T13:32:44.269895Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Supported Device:  cuda:1\n"]}],"source":["from tqdm import tqdm\n","from pathlib import Path\n","\n","import numpy as np\n","import pandas as pd\n","import polars as pl\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","\n","torch.manual_seed(996)\n","\n","DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n","# DEVICE = torch.device(\"cpu\")\n","print(\"Supported Device: \", DEVICE)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.335547Z","iopub.status.busy":"2024-06-03T13:32:49.334389Z","iopub.status.idle":"2024-06-03T13:32:49.341463Z","shell.execute_reply":"2024-06-03T13:32:49.340451Z","shell.execute_reply.started":"2024-06-03T13:32:49.335490Z"},"trusted":true},"outputs":[],"source":["# EXT_SRC: It contains 1 million randomly selected and shuffled rows from the original dataset.\n","\n","ROOT = Path(\"/data/ycw/Clim\")\n","EXT_SRC = Path(\"/data/ycw/Clim\")\n","\n","TRAIN_PATH = \"/data/ycw/competitions/leap-atmospheric-physics-ai-climsim/train.csv\"\n","#TRAIN_PATH = EXT_SRC / \"train_sampled_1m.parquet\"\n","TEST_PATH = ROOT / \"test.csv\"\n","SUBMISSION_PATH = ROOT / \"sample_submission.csv\"\n","\n","NUM_EPOCHS = 15\n","BATCH_SIZE = 128\n","LEARNING_RATE = 3e-4\n","ERR = 1e-6\n","\n","TRAIN_SIZE = 8091520\n","VALID_SIZE = 2000000\n","# TRAIN_SIZE = 800000\n","# VALID_SIZE = 200000\n","\n","DIM_FEATURES = 556\n","DIM_TARGETS = 368"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.343837Z","iopub.status.busy":"2024-06-03T13:32:49.343468Z","iopub.status.idle":"2024-06-03T13:32:49.471555Z","shell.execute_reply":"2024-06-03T13:32:49.470585Z","shell.execute_reply.started":"2024-06-03T13:32:49.343808Z"},"trusted":true},"outputs":[],"source":["ID = \"sample_id\"\n","\n","# INPUT COLUMNS\n","\n","STATE_PS = \"state_ps\"\n","\n","PBUF_SOLIN = \"pbuf_SOLIN\"\n","PBUF_LHFLX = \"pbuf_LHFLX\"\n","PBUF_SHFLX = \"pbuf_SHFLX\"\n","PBUF_TAUX = \"pbuf_TAUX\"\n","PBUF_TAUY = \"pbuf_TAUY\"\n","PBUF_COSZRS = \"pbuf_COSZRS\"\n","\n","CAM_IN_ALDIF = \"cam_in_ALDIF\"\n","CAM_IN_ALDIR = \"cam_in_ALDIR\"\n","CAM_IN_ASDIF = \"cam_in_ASDIF\"\n","CAM_IN_ASDIR = \"cam_in_ASDIR\"\n","CAM_IN_LWUP = \"cam_in_LWUP\"\n","CAM_IN_ICEFRAC = \"cam_in_ICEFRAC\"\n","CAM_IN_LANDFRAC = \"cam_in_LANDFRAC\"\n","CAM_IN_OCNFRAC = \"cam_in_OCNFRAC\"\n","CAM_IN_SNOWHLAND = \"cam_in_SNOWHLAND\"\n","\n","STATE_U = ['state_u_0', 'state_u_1', 'state_u_2', 'state_u_3', 'state_u_4', 'state_u_5', 'state_u_6', 'state_u_7', 'state_u_8', 'state_u_9', 'state_u_10', 'state_u_11', 'state_u_12', 'state_u_13', 'state_u_14', 'state_u_15', 'state_u_16', 'state_u_17', 'state_u_18', 'state_u_19', 'state_u_20', 'state_u_21', 'state_u_22', 'state_u_23', 'state_u_24', 'state_u_25', 'state_u_26', 'state_u_27', 'state_u_28', 'state_u_29', 'state_u_30', 'state_u_31', 'state_u_32', 'state_u_33', 'state_u_34', 'state_u_35', 'state_u_36', 'state_u_37', 'state_u_38', 'state_u_39', 'state_u_40', 'state_u_41', 'state_u_42', 'state_u_43', 'state_u_44', 'state_u_45', 'state_u_46', 'state_u_47', 'state_u_48', 'state_u_49', 'state_u_50', 'state_u_51', 'state_u_52', 'state_u_53', 'state_u_54', 'state_u_55', 'state_u_56', 'state_u_57', 'state_u_58', 'state_u_59']\n","STATE_V = ['state_v_0', 'state_v_1', 'state_v_2', 'state_v_3', 'state_v_4', 'state_v_5', 'state_v_6', 'state_v_7', 'state_v_8', 'state_v_9', 'state_v_10', 'state_v_11', 'state_v_12', 'state_v_13', 'state_v_14', 'state_v_15', 'state_v_16', 'state_v_17', 'state_v_18', 'state_v_19', 'state_v_20', 'state_v_21', 'state_v_22', 'state_v_23', 'state_v_24', 'state_v_25', 'state_v_26', 'state_v_27', 'state_v_28', 'state_v_29', 'state_v_30', 'state_v_31', 'state_v_32', 'state_v_33', 'state_v_34', 'state_v_35', 'state_v_36', 'state_v_37', 'state_v_38', 'state_v_39', 'state_v_40', 'state_v_41', 'state_v_42', 'state_v_43', 'state_v_44', 'state_v_45', 'state_v_46', 'state_v_47', 'state_v_48', 'state_v_49', 'state_v_50', 'state_v_51', 'state_v_52', 'state_v_53', 'state_v_54', 'state_v_55', 'state_v_56', 'state_v_57', 'state_v_58', 'state_v_59']\n","STATE_T = ['state_t_0', 'state_t_1', 'state_t_2', 'state_t_3', 'state_t_4', 'state_t_5', 'state_t_6', 'state_t_7', 'state_t_8', 'state_t_9', 'state_t_10', 'state_t_11', 'state_t_12', 'state_t_13', 'state_t_14', 'state_t_15', 'state_t_16', 'state_t_17', 'state_t_18', 'state_t_19', 'state_t_20', 'state_t_21', 'state_t_22', 'state_t_23', 'state_t_24', 'state_t_25', 'state_t_26', 'state_t_27', 'state_t_28', 'state_t_29', 'state_t_30', 'state_t_31', 'state_t_32', 'state_t_33', 'state_t_34', 'state_t_35', 'state_t_36', 'state_t_37', 'state_t_38', 'state_t_39', 'state_t_40', 'state_t_41', 'state_t_42', 'state_t_43', 'state_t_44', 'state_t_45', 'state_t_46', 'state_t_47', 'state_t_48', 'state_t_49', 'state_t_50', 'state_t_51', 'state_t_52', 'state_t_53', 'state_t_54', 'state_t_55', 'state_t_56', 'state_t_57', 'state_t_58', 'state_t_59']\n","\n","STATE_Q0001 = ['state_q0001_0', 'state_q0001_1', 'state_q0001_2', 'state_q0001_3', 'state_q0001_4', 'state_q0001_5', 'state_q0001_6', 'state_q0001_7', 'state_q0001_8', 'state_q0001_9', 'state_q0001_10', 'state_q0001_11', 'state_q0001_12', 'state_q0001_13', 'state_q0001_14', 'state_q0001_15', 'state_q0001_16', 'state_q0001_17', 'state_q0001_18', 'state_q0001_19', 'state_q0001_20', 'state_q0001_21', 'state_q0001_22', 'state_q0001_23', 'state_q0001_24', 'state_q0001_25', 'state_q0001_26', 'state_q0001_27', 'state_q0001_28', 'state_q0001_29', 'state_q0001_30', 'state_q0001_31', 'state_q0001_32', 'state_q0001_33', 'state_q0001_34', 'state_q0001_35', 'state_q0001_36', 'state_q0001_37', 'state_q0001_38', 'state_q0001_39', 'state_q0001_40', 'state_q0001_41', 'state_q0001_42', 'state_q0001_43', 'state_q0001_44', 'state_q0001_45', 'state_q0001_46', 'state_q0001_47', 'state_q0001_48', 'state_q0001_49', 'state_q0001_50', 'state_q0001_51', 'state_q0001_52', 'state_q0001_53', 'state_q0001_54', 'state_q0001_55', 'state_q0001_56', 'state_q0001_57', 'state_q0001_58', 'state_q0001_59']\n","STATE_Q0002 = ['state_q0002_0', 'state_q0002_1', 'state_q0002_2', 'state_q0002_3', 'state_q0002_4', 'state_q0002_5', 'state_q0002_6', 'state_q0002_7', 'state_q0002_8', 'state_q0002_9', 'state_q0002_10', 'state_q0002_11', 'state_q0002_12', 'state_q0002_13', 'state_q0002_14', 'state_q0002_15', 'state_q0002_16', 'state_q0002_17', 'state_q0002_18', 'state_q0002_19', 'state_q0002_20', 'state_q0002_21', 'state_q0002_22', 'state_q0002_23', 'state_q0002_24', 'state_q0002_25', 'state_q0002_26', 'state_q0002_27', 'state_q0002_28', 'state_q0002_29', 'state_q0002_30', 'state_q0002_31', 'state_q0002_32', 'state_q0002_33', 'state_q0002_34', 'state_q0002_35', 'state_q0002_36', 'state_q0002_37', 'state_q0002_38', 'state_q0002_39', 'state_q0002_40', 'state_q0002_41', 'state_q0002_42', 'state_q0002_43', 'state_q0002_44', 'state_q0002_45', 'state_q0002_46', 'state_q0002_47', 'state_q0002_48', 'state_q0002_49', 'state_q0002_50', 'state_q0002_51', 'state_q0002_52', 'state_q0002_53', 'state_q0002_54', 'state_q0002_55', 'state_q0002_56', 'state_q0002_57', 'state_q0002_58', 'state_q0002_59']\n","STATE_Q0003 = ['state_q0003_0', 'state_q0003_1', 'state_q0003_2', 'state_q0003_3', 'state_q0003_4', 'state_q0003_5', 'state_q0003_6', 'state_q0003_7', 'state_q0003_8', 'state_q0003_9', 'state_q0003_10', 'state_q0003_11', 'state_q0003_12', 'state_q0003_13', 'state_q0003_14', 'state_q0003_15', 'state_q0003_16', 'state_q0003_17', 'state_q0003_18', 'state_q0003_19', 'state_q0003_20', 'state_q0003_21', 'state_q0003_22', 'state_q0003_23', 'state_q0003_24', 'state_q0003_25', 'state_q0003_26', 'state_q0003_27', 'state_q0003_28', 'state_q0003_29', 'state_q0003_30', 'state_q0003_31', 'state_q0003_32', 'state_q0003_33', 'state_q0003_34', 'state_q0003_35', 'state_q0003_36', 'state_q0003_37', 'state_q0003_38', 'state_q0003_39', 'state_q0003_40', 'state_q0003_41', 'state_q0003_42', 'state_q0003_43', 'state_q0003_44', 'state_q0003_45', 'state_q0003_46', 'state_q0003_47', 'state_q0003_48', 'state_q0003_49', 'state_q0003_50', 'state_q0003_51', 'state_q0003_52', 'state_q0003_53', 'state_q0003_54', 'state_q0003_55', 'state_q0003_56', 'state_q0003_57', 'state_q0003_58', 'state_q0003_59']\n","\n","PBUF_OZONE = ['pbuf_ozone_0', 'pbuf_ozone_1', 'pbuf_ozone_2', 'pbuf_ozone_3', 'pbuf_ozone_4', 'pbuf_ozone_5', 'pbuf_ozone_6', 'pbuf_ozone_7', 'pbuf_ozone_8', 'pbuf_ozone_9', 'pbuf_ozone_10', 'pbuf_ozone_11', 'pbuf_ozone_12', 'pbuf_ozone_13', 'pbuf_ozone_14', 'pbuf_ozone_15', 'pbuf_ozone_16', 'pbuf_ozone_17', 'pbuf_ozone_18', 'pbuf_ozone_19', 'pbuf_ozone_20', 'pbuf_ozone_21', 'pbuf_ozone_22', 'pbuf_ozone_23', 'pbuf_ozone_24', 'pbuf_ozone_25', 'pbuf_ozone_26', 'pbuf_ozone_27', 'pbuf_ozone_28', 'pbuf_ozone_29', 'pbuf_ozone_30', 'pbuf_ozone_31', 'pbuf_ozone_32', 'pbuf_ozone_33', 'pbuf_ozone_34', 'pbuf_ozone_35', 'pbuf_ozone_36', 'pbuf_ozone_37', 'pbuf_ozone_38', 'pbuf_ozone_39', 'pbuf_ozone_40', 'pbuf_ozone_41', 'pbuf_ozone_42', 'pbuf_ozone_43', 'pbuf_ozone_44', 'pbuf_ozone_45', 'pbuf_ozone_46', 'pbuf_ozone_47', 'pbuf_ozone_48', 'pbuf_ozone_49', 'pbuf_ozone_50', 'pbuf_ozone_51', 'pbuf_ozone_52', 'pbuf_ozone_53', 'pbuf_ozone_54', 'pbuf_ozone_55', 'pbuf_ozone_56', 'pbuf_ozone_57', 'pbuf_ozone_58', 'pbuf_ozone_59']\n","PBUF_CH4 = ['pbuf_CH4_0', 'pbuf_CH4_1', 'pbuf_CH4_2', 'pbuf_CH4_3', 'pbuf_CH4_4', 'pbuf_CH4_5', 'pbuf_CH4_6', 'pbuf_CH4_7', 'pbuf_CH4_8', 'pbuf_CH4_9', 'pbuf_CH4_10', 'pbuf_CH4_11', 'pbuf_CH4_12', 'pbuf_CH4_13', 'pbuf_CH4_14', 'pbuf_CH4_15', 'pbuf_CH4_16', 'pbuf_CH4_17', 'pbuf_CH4_18', 'pbuf_CH4_19', 'pbuf_CH4_20', 'pbuf_CH4_21', 'pbuf_CH4_22', 'pbuf_CH4_23', 'pbuf_CH4_24', 'pbuf_CH4_25', 'pbuf_CH4_26', 'pbuf_CH4_27', 'pbuf_CH4_28', 'pbuf_CH4_29', 'pbuf_CH4_30', 'pbuf_CH4_31', 'pbuf_CH4_32', 'pbuf_CH4_33', 'pbuf_CH4_34', 'pbuf_CH4_35', 'pbuf_CH4_36', 'pbuf_CH4_37', 'pbuf_CH4_38', 'pbuf_CH4_39', 'pbuf_CH4_40', 'pbuf_CH4_41', 'pbuf_CH4_42', 'pbuf_CH4_43', 'pbuf_CH4_44', 'pbuf_CH4_45', 'pbuf_CH4_46', 'pbuf_CH4_47', 'pbuf_CH4_48', 'pbuf_CH4_49', 'pbuf_CH4_50', 'pbuf_CH4_51', 'pbuf_CH4_52', 'pbuf_CH4_53', 'pbuf_CH4_54', 'pbuf_CH4_55', 'pbuf_CH4_56', 'pbuf_CH4_57', 'pbuf_CH4_58', 'pbuf_CH4_59']\n","PBUF_N2O = ['pbuf_N2O_0', 'pbuf_N2O_1', 'pbuf_N2O_2', 'pbuf_N2O_3', 'pbuf_N2O_4', 'pbuf_N2O_5', 'pbuf_N2O_6', 'pbuf_N2O_7', 'pbuf_N2O_8', 'pbuf_N2O_9', 'pbuf_N2O_10', 'pbuf_N2O_11', 'pbuf_N2O_12', 'pbuf_N2O_13', 'pbuf_N2O_14', 'pbuf_N2O_15', 'pbuf_N2O_16', 'pbuf_N2O_17', 'pbuf_N2O_18', 'pbuf_N2O_19', 'pbuf_N2O_20', 'pbuf_N2O_21', 'pbuf_N2O_22', 'pbuf_N2O_23', 'pbuf_N2O_24', 'pbuf_N2O_25', 'pbuf_N2O_26', 'pbuf_N2O_27', 'pbuf_N2O_28', 'pbuf_N2O_29', 'pbuf_N2O_30', 'pbuf_N2O_31', 'pbuf_N2O_32', 'pbuf_N2O_33', 'pbuf_N2O_34', 'pbuf_N2O_35', 'pbuf_N2O_36', 'pbuf_N2O_37', 'pbuf_N2O_38', 'pbuf_N2O_39', 'pbuf_N2O_40', 'pbuf_N2O_41', 'pbuf_N2O_42', 'pbuf_N2O_43', 'pbuf_N2O_44', 'pbuf_N2O_45', 'pbuf_N2O_46', 'pbuf_N2O_47', 'pbuf_N2O_48', 'pbuf_N2O_49', 'pbuf_N2O_50', 'pbuf_N2O_51', 'pbuf_N2O_52', 'pbuf_N2O_53', 'pbuf_N2O_54', 'pbuf_N2O_55', 'pbuf_N2O_56', 'pbuf_N2O_57', 'pbuf_N2O_58', 'pbuf_N2O_59']\n","\n","# OUTPUT COLUMNS\n","\n","CAM_OUT_NETSW = \"cam_out_NETSW\"\n","CAM_OUT_FLWDS = \"cam_out_FLWDS\"\n","CAM_OUT_PRECSC = \"cam_out_PRECSC\"\n","CAM_OUT_PRECC = \"cam_out_PRECC\"\n","CAM_OUT_SOLS = \"cam_out_SOLS\"\n","CAM_OUT_SOLL = \"cam_out_SOLL\"\n","CAM_OUT_SOLSD = \"cam_out_SOLSD\"\n","CAM_OUT_SOLLD = \"cam_out_SOLLD\"\n","\n","PTEND_Q0001 = ['ptend_q0001_0', 'ptend_q0001_1', 'ptend_q0001_2', 'ptend_q0001_3', 'ptend_q0001_4', 'ptend_q0001_5', 'ptend_q0001_6', 'ptend_q0001_7', 'ptend_q0001_8', 'ptend_q0001_9', 'ptend_q0001_10', 'ptend_q0001_11', 'ptend_q0001_12', 'ptend_q0001_13', 'ptend_q0001_14', 'ptend_q0001_15', 'ptend_q0001_16', 'ptend_q0001_17', 'ptend_q0001_18', 'ptend_q0001_19', 'ptend_q0001_20', 'ptend_q0001_21', 'ptend_q0001_22', 'ptend_q0001_23', 'ptend_q0001_24', 'ptend_q0001_25', 'ptend_q0001_26', 'ptend_q0001_27', 'ptend_q0001_28', 'ptend_q0001_29', 'ptend_q0001_30', 'ptend_q0001_31', 'ptend_q0001_32', 'ptend_q0001_33', 'ptend_q0001_34', 'ptend_q0001_35', 'ptend_q0001_36', 'ptend_q0001_37', 'ptend_q0001_38', 'ptend_q0001_39', 'ptend_q0001_40', 'ptend_q0001_41', 'ptend_q0001_42', 'ptend_q0001_43', 'ptend_q0001_44', 'ptend_q0001_45', 'ptend_q0001_46', 'ptend_q0001_47', 'ptend_q0001_48', 'ptend_q0001_49', 'ptend_q0001_50', 'ptend_q0001_51', 'ptend_q0001_52', 'ptend_q0001_53', 'ptend_q0001_54', 'ptend_q0001_55', 'ptend_q0001_56', 'ptend_q0001_57', 'ptend_q0001_58', 'ptend_q0001_59']\n","PTEND_Q0002 = ['ptend_q0002_0', 'ptend_q0002_1', 'ptend_q0002_2', 'ptend_q0002_3', 'ptend_q0002_4', 'ptend_q0002_5', 'ptend_q0002_6', 'ptend_q0002_7', 'ptend_q0002_8', 'ptend_q0002_9', 'ptend_q0002_10', 'ptend_q0002_11', 'ptend_q0002_12', 'ptend_q0002_13', 'ptend_q0002_14', 'ptend_q0002_15', 'ptend_q0002_16', 'ptend_q0002_17', 'ptend_q0002_18', 'ptend_q0002_19', 'ptend_q0002_20', 'ptend_q0002_21', 'ptend_q0002_22', 'ptend_q0002_23', 'ptend_q0002_24', 'ptend_q0002_25', 'ptend_q0002_26', 'ptend_q0002_27', 'ptend_q0002_28', 'ptend_q0002_29', 'ptend_q0002_30', 'ptend_q0002_31', 'ptend_q0002_32', 'ptend_q0002_33', 'ptend_q0002_34', 'ptend_q0002_35', 'ptend_q0002_36', 'ptend_q0002_37', 'ptend_q0002_38', 'ptend_q0002_39', 'ptend_q0002_40', 'ptend_q0002_41', 'ptend_q0002_42', 'ptend_q0002_43', 'ptend_q0002_44', 'ptend_q0002_45', 'ptend_q0002_46', 'ptend_q0002_47', 'ptend_q0002_48', 'ptend_q0002_49', 'ptend_q0002_50', 'ptend_q0002_51', 'ptend_q0002_52', 'ptend_q0002_53', 'ptend_q0002_54', 'ptend_q0002_55', 'ptend_q0002_56', 'ptend_q0002_57', 'ptend_q0002_58', 'ptend_q0002_59']\n","PTEND_Q0003 = ['ptend_q0003_0', 'ptend_q0003_1', 'ptend_q0003_2', 'ptend_q0003_3', 'ptend_q0003_4', 'ptend_q0003_5', 'ptend_q0003_6', 'ptend_q0003_7', 'ptend_q0003_8', 'ptend_q0003_9', 'ptend_q0003_10', 'ptend_q0003_11', 'ptend_q0003_12', 'ptend_q0003_13', 'ptend_q0003_14', 'ptend_q0003_15', 'ptend_q0003_16', 'ptend_q0003_17', 'ptend_q0003_18', 'ptend_q0003_19', 'ptend_q0003_20', 'ptend_q0003_21', 'ptend_q0003_22', 'ptend_q0003_23', 'ptend_q0003_24', 'ptend_q0003_25', 'ptend_q0003_26', 'ptend_q0003_27', 'ptend_q0003_28', 'ptend_q0003_29', 'ptend_q0003_30', 'ptend_q0003_31', 'ptend_q0003_32', 'ptend_q0003_33', 'ptend_q0003_34', 'ptend_q0003_35', 'ptend_q0003_36', 'ptend_q0003_37', 'ptend_q0003_38', 'ptend_q0003_39', 'ptend_q0003_40', 'ptend_q0003_41', 'ptend_q0003_42', 'ptend_q0003_43', 'ptend_q0003_44', 'ptend_q0003_45', 'ptend_q0003_46', 'ptend_q0003_47', 'ptend_q0003_48', 'ptend_q0003_49', 'ptend_q0003_50', 'ptend_q0003_51', 'ptend_q0003_52', 'ptend_q0003_53', 'ptend_q0003_54', 'ptend_q0003_55', 'ptend_q0003_56', 'ptend_q0003_57', 'ptend_q0003_58', 'ptend_q0003_59']\n","\n","PTEND_U = ['ptend_u_0', 'ptend_u_1', 'ptend_u_2', 'ptend_u_3', 'ptend_u_4', 'ptend_u_5', 'ptend_u_6', 'ptend_u_7', 'ptend_u_8', 'ptend_u_9', 'ptend_u_10', 'ptend_u_11', 'ptend_u_12', 'ptend_u_13', 'ptend_u_14', 'ptend_u_15', 'ptend_u_16', 'ptend_u_17', 'ptend_u_18', 'ptend_u_19', 'ptend_u_20', 'ptend_u_21', 'ptend_u_22', 'ptend_u_23', 'ptend_u_24', 'ptend_u_25', 'ptend_u_26', 'ptend_u_27', 'ptend_u_28', 'ptend_u_29', 'ptend_u_30', 'ptend_u_31', 'ptend_u_32', 'ptend_u_33', 'ptend_u_34', 'ptend_u_35', 'ptend_u_36', 'ptend_u_37', 'ptend_u_38', 'ptend_u_39', 'ptend_u_40', 'ptend_u_41', 'ptend_u_42', 'ptend_u_43', 'ptend_u_44', 'ptend_u_45', 'ptend_u_46', 'ptend_u_47', 'ptend_u_48', 'ptend_u_49', 'ptend_u_50', 'ptend_u_51', 'ptend_u_52', 'ptend_u_53', 'ptend_u_54', 'ptend_u_55', 'ptend_u_56', 'ptend_u_57', 'ptend_u_58', 'ptend_u_59']\n","PTEND_V = ['ptend_v_0', 'ptend_v_1', 'ptend_v_2', 'ptend_v_3', 'ptend_v_4', 'ptend_v_5', 'ptend_v_6', 'ptend_v_7', 'ptend_v_8', 'ptend_v_9', 'ptend_v_10', 'ptend_v_11', 'ptend_v_12', 'ptend_v_13', 'ptend_v_14', 'ptend_v_15', 'ptend_v_16', 'ptend_v_17', 'ptend_v_18', 'ptend_v_19', 'ptend_v_20', 'ptend_v_21', 'ptend_v_22', 'ptend_v_23', 'ptend_v_24', 'ptend_v_25', 'ptend_v_26', 'ptend_v_27', 'ptend_v_28', 'ptend_v_29', 'ptend_v_30', 'ptend_v_31', 'ptend_v_32', 'ptend_v_33', 'ptend_v_34', 'ptend_v_35', 'ptend_v_36', 'ptend_v_37', 'ptend_v_38', 'ptend_v_39', 'ptend_v_40', 'ptend_v_41', 'ptend_v_42', 'ptend_v_43', 'ptend_v_44', 'ptend_v_45', 'ptend_v_46', 'ptend_v_47', 'ptend_v_48', 'ptend_v_49', 'ptend_v_50', 'ptend_v_51', 'ptend_v_52', 'ptend_v_53', 'ptend_v_54', 'ptend_v_55', 'ptend_v_56', 'ptend_v_57', 'ptend_v_58', 'ptend_v_59']\n","PTEND_T = ['ptend_t_0', 'ptend_t_1', 'ptend_t_2', 'ptend_t_3', 'ptend_t_4', 'ptend_t_5', 'ptend_t_6', 'ptend_t_7', 'ptend_t_8', 'ptend_t_9', 'ptend_t_10', 'ptend_t_11', 'ptend_t_12', 'ptend_t_13', 'ptend_t_14', 'ptend_t_15', 'ptend_t_16', 'ptend_t_17', 'ptend_t_18', 'ptend_t_19', 'ptend_t_20', 'ptend_t_21', 'ptend_t_22', 'ptend_t_23', 'ptend_t_24', 'ptend_t_25', 'ptend_t_26', 'ptend_t_27', 'ptend_t_28', 'ptend_t_29', 'ptend_t_30', 'ptend_t_31', 'ptend_t_32', 'ptend_t_33', 'ptend_t_34', 'ptend_t_35', 'ptend_t_36', 'ptend_t_37', 'ptend_t_38', 'ptend_t_39', 'ptend_t_40', 'ptend_t_41', 'ptend_t_42', 'ptend_t_43', 'ptend_t_44', 'ptend_t_45', 'ptend_t_46', 'ptend_t_47', 'ptend_t_48', 'ptend_t_49', 'ptend_t_50', 'ptend_t_51', 'ptend_t_52', 'ptend_t_53', 'ptend_t_54', 'ptend_t_55', 'ptend_t_56', 'ptend_t_57', 'ptend_t_58', 'ptend_t_59']\n","\n","# REPLACEMENT COLUMNS\n","\n","REPLACE_FROM = ['ptend_q0002_0', 'ptend_q0002_1', 'ptend_q0002_2', 'ptend_q0002_3', 'ptend_q0002_4', 'ptend_q0002_5', 'ptend_q0002_6', 'ptend_q0002_7', 'ptend_q0002_8', 'ptend_q0002_9', 'ptend_q0002_10', 'ptend_q0002_11', 'ptend_q0002_12', 'ptend_q0002_13', 'ptend_q0002_14', 'ptend_q0002_15', 'ptend_q0002_16', 'ptend_q0002_17', 'ptend_q0002_18', 'ptend_q0002_19', 'ptend_q0002_20', 'ptend_q0002_21', 'ptend_q0002_22', 'ptend_q0002_23', 'ptend_q0002_24', 'ptend_q0002_25', 'ptend_q0002_26']\n","REPLACE_TO = ['state_q0002_0', 'state_q0002_1', 'state_q0002_2', 'state_q0002_3', 'state_q0002_4', 'state_q0002_5', 'state_q0002_6', 'state_q0002_7', 'state_q0002_8', 'state_q0002_9', 'state_q0002_10', 'state_q0002_11', 'state_q0002_12', 'state_q0002_13', 'state_q0002_14', 'state_q0002_15', 'state_q0002_16', 'state_q0002_17', 'state_q0002_18', 'state_q0002_19', 'state_q0002_20', 'state_q0002_21', 'state_q0002_22', 'state_q0002_23', 'state_q0002_24', 'state_q0002_25', 'state_q0002_26']\n","\n","# TARGET WEIGHTS\n","\n","TARGET_WEIGHTS = [30981.265271661872, 22502.432413914863, 18894.14713004499, 14514.244730542465, 10944.348069459196, 9065.01072024503, 9663.669038687454, 12688.557362943708, 19890.17226527665, 25831.37317235381, 33890.367561807274, 44122.94111025334, 59811.25595068309, 79434.07500078829, 107358.80916894016, 135720.8418348218, 149399.8411114814, 128492.95185325432, 91746.23687305572, 72748.76911097553, 66531.53596840335, 62932.30598423903, 56610.26874314136, 49473.14369220607, 43029.18495420936, 36912.67491908133, 31486.93117928144, 26898.072997215502, 23316.638282978325, 20459.73133196152, 18385.68309639014, 17111.405107656312, 16337.80991958771, 15857.759882318944, 15580.902485189716, 15497.59045982052, 15612.2556996736, 15797.88455410361, 15974.218740897895, 16130.395527176632, 16261.310866446129, 16371.892401608216, 16397.019695140876, 16325.463899570548, 16228.641108112768, 16191.809643436269, 16341.207925934068, 16645.711351490587, 17005.493716683693, 17430.29874509864, 17907.24023203076, 18431.55334008694, 19032.471309392287, 19701.355113141435, 20408.236605392685, 20967.20795006453, 21194.427318009974, 21088.521528526755, 19437.91555757985, 13677.902713248171, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 871528441401.8333, 1083221770553.0684, 147034752676.7702, 35556045575.13566, 35153369257.41337, 46086368691.51654, 24689305171.692936, 11343276593.440475, 5396624651.94418, 2449353007.641508, 1132225885.703891, 579547849.1340877, 330219246.7861086, 207613930.3131764, 144580292.27473342, 109933282.92266414, 88706603.092171, 73819777.54163922, 63615988.74519494, 57250262.292053565, 52976073.06761927, 49653169.17819005, 46544975.11484598, 43167606.9599748, 39724375.20499403, 36317177.25886468, 33057511.80930482, 29869089.497658804, 26982386.85583376, 24416235.17215712, 22273651.697369896, 20553426.04804544, 19216240.03357431, 18167694.44812838, 17501855.536957663, 17169938.630597908, 17005382.258644175, 16998475.26752617, 17082890.987979066, 17227982.77516062, 17445823.21630204, 17757404.421785507, 18346092.75160569, 19400573.66632694, 20506722.48296608, 22469648.380506545, 23432031.455169585, 26204163.40545158, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 1000000000000000.0, 3673829810926.31, 371405570725.2526, 14219163611.984406, 3001863018.1934915, 1432766589.9326108, 884599805.0283787, 560127980.1033351, 386052567.7087711, 287331851.051439, 222703657.59538063, 181069239.6264349, 154620864.3164144, 138093777.60284117, 126605828.89875436, 117967840.02553518, 111005814.39518328, 105186901.20678852, 100168133.0295481, 95568646.67416307, 91457433.39515457, 88871610.45308323, 88829796.26374224, 91398113.73291488, 96585131.67000748, 104507692.01463065, 115895119.998433, 131939701.08213414, 154492946.00677127, 183147918.17086875, 215151374.22324687, 247158314.6345976, 266792879.42215955, 279115128.29108113, 370541510.87006927, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 877670509694.7871, 1174826943136.8308, 1270605570069.038, 21727315470.5208, 3159456646.5437946, 1090653401.282219, 727967089.8459107, 384399548.9506704, 290787296.9451616, 232703218.45048887, 197467462.7577736, 174310890.8025987, 160536437.73297343, 153567098.77048483, 152120124.9453068, 153115566.6756177, 153955545.42558223, 153734675.21565756, 154798666.36905554, 163346213.58113608, 180013139.3707387, 200324358.8534948, 220754613.1646765, 241290935.478592, 262868932.2066308, 284448910.01847774, 305681084.4142859, 327605088.8575117, 350473296.7263526, 373964594.1196182, 398396925.8173239, 423528355.65716046, 450447055.544388, 478857006.4973163, 508200335.7126168, 537309657.5789208, 566854568.2904652, 594618842.9455439, 619715928.2391286, 641395460.8414665, 663290039.7810476, 689274894.631561, 718208866.3397261, 743951200.8024124, 761776104.2945968, 772911224.3082078, 804001144.8046833, 772448774.7758856, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4613823.568205323, 1999308.9343799097, 904636.2296014762, 433823.6123842511, 207201.39055371704, 107836.09164720173, 57647.915219220784, 40606.52305039815, 47739.86647922776, 51669.35493930698, 56438.19768395407, 60447.45665200092, 65251.4153955275, 71920.88588011517, 78529.58115204438, 83422.30217897324, 87036.98552475807, 90389.72631774022, 93982.39165674087, 97578.0099352472, 101428.21366062944, 104630.69200130588, 105685.04322626138, 103962.58423268417, 99650.31670632094, 94290.49986206587, 89514.90144353417, 85905.45713126978, 82784.9857650212, 79152.28707014346, 74847.81017353121, 70378.81859610273, 65420.04643792357, 59953.75184604176, 54764.28281143022, 50362.51288353384, 46212.571031725325, 41997.52779088816, 37692.05148110484, 33834.73460995647, 31846.09764364542, 31934.145655397457, 31454.81247448105, 30105.4073072481, 26957.830283611693, 27760.04479210889, 29853.374336459365, 19133.428743715107, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7619940.584531054, 3148394.472742347, 1308415.0022178134, 540515.7720745018, 215237.1053603881, 102546.7276372816, 68453.67122640925, 50692.59053608593, 51487.52043139844, 52104.76838400132, 54019.39151917722, 55856.02168787862, 60347.30240270209, 68990.96019017675, 79096.88768563846, 87574.33453690328, 94158.56052476274, 101903.63670531697, 111746.9753834774, 122460.65399236557, 132086.69387474353, 141041.48571028374, 146354.09441287292, 145953.09590059065, 139496.8007888401, 128508.85108217449, 116665.51769667884, 107458.39706309135, 100259.97236694951, 94108.98505029618, 88439.89456238014, 82734.9027659809, 77061.08621371102, 71333.5319243128, 65999.72532130677, 61798.9972058361, 58237.356419617165, 54715.10266341248, 50825.84431702935, 46059.17688689915, 40740.26050401376, 36335.80228304863, 33981.57568605091, 33589.7143390849, 33988.88524112733, 36272.9364507092, 41183.34413717943, 29194.12369278645, 0.0040536134869726, 0.0138824238058072, 135129884.5084534, 12219717.5342461, 0.0090705273332672, 0.0085898851680217, 0.0215368188774867, 0.0336321308942602]\n","\n","# FEATURE & TARGET LIST\n","FEATURE_NAMES = ['state_t_0', 'state_t_1', 'state_t_2', 'state_t_3', 'state_t_4', 'state_t_5', 'state_t_6', 'state_t_7', 'state_t_8', 'state_t_9', 'state_t_10', 'state_t_11', 'state_t_12', 'state_t_13', 'state_t_14', 'state_t_15', 'state_t_16', 'state_t_17', 'state_t_18', 'state_t_19', 'state_t_20', 'state_t_21', 'state_t_22', 'state_t_23', 'state_t_24', 'state_t_25', 'state_t_26', 'state_t_27', 'state_t_28', 'state_t_29', 'state_t_30', 'state_t_31', 'state_t_32', 'state_t_33', 'state_t_34', 'state_t_35', 'state_t_36', 'state_t_37', 'state_t_38', 'state_t_39', 'state_t_40', 'state_t_41', 'state_t_42', 'state_t_43', 'state_t_44', 'state_t_45', 'state_t_46', 'state_t_47', 'state_t_48', 'state_t_49', 'state_t_50', 'state_t_51', 'state_t_52', 'state_t_53', 'state_t_54', 'state_t_55', 'state_t_56', 'state_t_57', 'state_t_58', 'state_t_59', 'state_q0001_0', 'state_q0001_1', 'state_q0001_2', 'state_q0001_3', 'state_q0001_4', 'state_q0001_5', 'state_q0001_6', 'state_q0001_7', 'state_q0001_8', 'state_q0001_9', 'state_q0001_10', 'state_q0001_11', 'state_q0001_12', 'state_q0001_13', 'state_q0001_14', 'state_q0001_15', 'state_q0001_16', 'state_q0001_17', 'state_q0001_18', 'state_q0001_19', 'state_q0001_20', 'state_q0001_21', 'state_q0001_22', 'state_q0001_23', 'state_q0001_24', 'state_q0001_25', 'state_q0001_26', 'state_q0001_27', 'state_q0001_28', 'state_q0001_29', 'state_q0001_30', 'state_q0001_31', 'state_q0001_32', 'state_q0001_33', 'state_q0001_34', 'state_q0001_35', 'state_q0001_36', 'state_q0001_37', 'state_q0001_38', 'state_q0001_39', 'state_q0001_40', 'state_q0001_41', 'state_q0001_42', 'state_q0001_43', 'state_q0001_44', 'state_q0001_45', 'state_q0001_46', 'state_q0001_47', 'state_q0001_48', 'state_q0001_49', 'state_q0001_50', 'state_q0001_51', 'state_q0001_52', 'state_q0001_53', 'state_q0001_54', 'state_q0001_55', 'state_q0001_56', 'state_q0001_57', 'state_q0001_58', 'state_q0001_59', 'state_q0002_0', 'state_q0002_1', 'state_q0002_2', 'state_q0002_3', 'state_q0002_4', 'state_q0002_5', 'state_q0002_6', 'state_q0002_7', 'state_q0002_8', 'state_q0002_9', 'state_q0002_10', 'state_q0002_11', 'state_q0002_12', 'state_q0002_13', 'state_q0002_14', 'state_q0002_15', 'state_q0002_16', 'state_q0002_17', 'state_q0002_18', 'state_q0002_19', 'state_q0002_20', 'state_q0002_21', 'state_q0002_22', 'state_q0002_23', 'state_q0002_24', 'state_q0002_25', 'state_q0002_26', 'state_q0002_27', 'state_q0002_28', 'state_q0002_29', 'state_q0002_30', 'state_q0002_31', 'state_q0002_32', 'state_q0002_33', 'state_q0002_34', 'state_q0002_35', 'state_q0002_36', 'state_q0002_37', 'state_q0002_38', 'state_q0002_39', 'state_q0002_40', 'state_q0002_41', 'state_q0002_42', 'state_q0002_43', 'state_q0002_44', 'state_q0002_45', 'state_q0002_46', 'state_q0002_47', 'state_q0002_48', 'state_q0002_49', 'state_q0002_50', 'state_q0002_51', 'state_q0002_52', 'state_q0002_53', 'state_q0002_54', 'state_q0002_55', 'state_q0002_56', 'state_q0002_57', 'state_q0002_58', 'state_q0002_59', 'state_q0003_0', 'state_q0003_1', 'state_q0003_2', 'state_q0003_3', 'state_q0003_4', 'state_q0003_5', 'state_q0003_6', 'state_q0003_7', 'state_q0003_8', 'state_q0003_9', 'state_q0003_10', 'state_q0003_11', 'state_q0003_12', 'state_q0003_13', 'state_q0003_14', 'state_q0003_15', 'state_q0003_16', 'state_q0003_17', 'state_q0003_18', 'state_q0003_19', 'state_q0003_20', 'state_q0003_21', 'state_q0003_22', 'state_q0003_23', 'state_q0003_24', 'state_q0003_25', 'state_q0003_26', 'state_q0003_27', 'state_q0003_28', 'state_q0003_29', 'state_q0003_30', 'state_q0003_31', 'state_q0003_32', 'state_q0003_33', 'state_q0003_34', 'state_q0003_35', 'state_q0003_36', 'state_q0003_37', 'state_q0003_38', 'state_q0003_39', 'state_q0003_40', 'state_q0003_41', 'state_q0003_42', 'state_q0003_43', 'state_q0003_44', 'state_q0003_45', 'state_q0003_46', 'state_q0003_47', 'state_q0003_48', 'state_q0003_49', 'state_q0003_50', 'state_q0003_51', 'state_q0003_52', 'state_q0003_53', 'state_q0003_54', 'state_q0003_55', 'state_q0003_56', 'state_q0003_57', 'state_q0003_58', 'state_q0003_59', 'state_u_0', 'state_u_1', 'state_u_2', 'state_u_3', 'state_u_4', 'state_u_5', 'state_u_6', 'state_u_7', 'state_u_8', 'state_u_9', 'state_u_10', 'state_u_11', 'state_u_12', 'state_u_13', 'state_u_14', 'state_u_15', 'state_u_16', 'state_u_17', 'state_u_18', 'state_u_19', 'state_u_20', 'state_u_21', 'state_u_22', 'state_u_23', 'state_u_24', 'state_u_25', 'state_u_26', 'state_u_27', 'state_u_28', 'state_u_29', 'state_u_30', 'state_u_31', 'state_u_32', 'state_u_33', 'state_u_34', 'state_u_35', 'state_u_36', 'state_u_37', 'state_u_38', 'state_u_39', 'state_u_40', 'state_u_41', 'state_u_42', 'state_u_43', 'state_u_44', 'state_u_45', 'state_u_46', 'state_u_47', 'state_u_48', 'state_u_49', 'state_u_50', 'state_u_51', 'state_u_52', 'state_u_53', 'state_u_54', 'state_u_55', 'state_u_56', 'state_u_57', 'state_u_58', 'state_u_59', 'state_v_0', 'state_v_1', 'state_v_2', 'state_v_3', 'state_v_4', 'state_v_5', 'state_v_6', 'state_v_7', 'state_v_8', 'state_v_9', 'state_v_10', 'state_v_11', 'state_v_12', 'state_v_13', 'state_v_14', 'state_v_15', 'state_v_16', 'state_v_17', 'state_v_18', 'state_v_19', 'state_v_20', 'state_v_21', 'state_v_22', 'state_v_23', 'state_v_24', 'state_v_25', 'state_v_26', 'state_v_27', 'state_v_28', 'state_v_29', 'state_v_30', 'state_v_31', 'state_v_32', 'state_v_33', 'state_v_34', 'state_v_35', 'state_v_36', 'state_v_37', 'state_v_38', 'state_v_39', 'state_v_40', 'state_v_41', 'state_v_42', 'state_v_43', 'state_v_44', 'state_v_45', 'state_v_46', 'state_v_47', 'state_v_48', 'state_v_49', 'state_v_50', 'state_v_51', 'state_v_52', 'state_v_53', 'state_v_54', 'state_v_55', 'state_v_56', 'state_v_57', 'state_v_58', 'state_v_59', 'pbuf_ozone_0', 'pbuf_ozone_1', 'pbuf_ozone_2', 'pbuf_ozone_3', 'pbuf_ozone_4', 'pbuf_ozone_5', 'pbuf_ozone_6', 'pbuf_ozone_7', 'pbuf_ozone_8', 'pbuf_ozone_9', 'pbuf_ozone_10', 'pbuf_ozone_11', 'pbuf_ozone_12', 'pbuf_ozone_13', 'pbuf_ozone_14', 'pbuf_ozone_15', 'pbuf_ozone_16', 'pbuf_ozone_17', 'pbuf_ozone_18', 'pbuf_ozone_19', 'pbuf_ozone_20', 'pbuf_ozone_21', 'pbuf_ozone_22', 'pbuf_ozone_23', 'pbuf_ozone_24', 'pbuf_ozone_25', 'pbuf_ozone_26', 'pbuf_ozone_27', 'pbuf_ozone_28', 'pbuf_ozone_29', 'pbuf_ozone_30', 'pbuf_ozone_31', 'pbuf_ozone_32', 'pbuf_ozone_33', 'pbuf_ozone_34', 'pbuf_ozone_35', 'pbuf_ozone_36', 'pbuf_ozone_37', 'pbuf_ozone_38', 'pbuf_ozone_39', 'pbuf_ozone_40', 'pbuf_ozone_41', 'pbuf_ozone_42', 'pbuf_ozone_43', 'pbuf_ozone_44', 'pbuf_ozone_45', 'pbuf_ozone_46', 'pbuf_ozone_47', 'pbuf_ozone_48', 'pbuf_ozone_49', 'pbuf_ozone_50', 'pbuf_ozone_51', 'pbuf_ozone_52', 'pbuf_ozone_53', 'pbuf_ozone_54', 'pbuf_ozone_55', 'pbuf_ozone_56', 'pbuf_ozone_57', 'pbuf_ozone_58', 'pbuf_ozone_59', 'pbuf_CH4_0', 'pbuf_CH4_1', 'pbuf_CH4_2', 'pbuf_CH4_3', 'pbuf_CH4_4', 'pbuf_CH4_5', 'pbuf_CH4_6', 'pbuf_CH4_7', 'pbuf_CH4_8', 'pbuf_CH4_9', 'pbuf_CH4_10', 'pbuf_CH4_11', 'pbuf_CH4_12', 'pbuf_CH4_13', 'pbuf_CH4_14', 'pbuf_CH4_15', 'pbuf_CH4_16', 'pbuf_CH4_17', 'pbuf_CH4_18', 'pbuf_CH4_19', 'pbuf_CH4_20', 'pbuf_CH4_21', 'pbuf_CH4_22', 'pbuf_CH4_23', 'pbuf_CH4_24', 'pbuf_CH4_25', 'pbuf_CH4_26', 'pbuf_CH4_27', 'pbuf_CH4_28', 'pbuf_CH4_29', 'pbuf_CH4_30', 'pbuf_CH4_31', 'pbuf_CH4_32', 'pbuf_CH4_33', 'pbuf_CH4_34', 'pbuf_CH4_35', 'pbuf_CH4_36', 'pbuf_CH4_37', 'pbuf_CH4_38', 'pbuf_CH4_39', 'pbuf_CH4_40', 'pbuf_CH4_41', 'pbuf_CH4_42', 'pbuf_CH4_43', 'pbuf_CH4_44', 'pbuf_CH4_45', 'pbuf_CH4_46', 'pbuf_CH4_47', 'pbuf_CH4_48', 'pbuf_CH4_49', 'pbuf_CH4_50', 'pbuf_CH4_51', 'pbuf_CH4_52', 'pbuf_CH4_53', 'pbuf_CH4_54', 'pbuf_CH4_55', 'pbuf_CH4_56', 'pbuf_CH4_57', 'pbuf_CH4_58', 'pbuf_CH4_59', 'pbuf_N2O_0', 'pbuf_N2O_1', 'pbuf_N2O_2', 'pbuf_N2O_3', 'pbuf_N2O_4', 'pbuf_N2O_5', 'pbuf_N2O_6', 'pbuf_N2O_7', 'pbuf_N2O_8', 'pbuf_N2O_9', 'pbuf_N2O_10', 'pbuf_N2O_11', 'pbuf_N2O_12', 'pbuf_N2O_13', 'pbuf_N2O_14', 'pbuf_N2O_15', 'pbuf_N2O_16', 'pbuf_N2O_17', 'pbuf_N2O_18', 'pbuf_N2O_19', 'pbuf_N2O_20', 'pbuf_N2O_21', 'pbuf_N2O_22', 'pbuf_N2O_23', 'pbuf_N2O_24', 'pbuf_N2O_25', 'pbuf_N2O_26', 'pbuf_N2O_27', 'pbuf_N2O_28', 'pbuf_N2O_29', 'pbuf_N2O_30', 'pbuf_N2O_31', 'pbuf_N2O_32', 'pbuf_N2O_33', 'pbuf_N2O_34', 'pbuf_N2O_35', 'pbuf_N2O_36', 'pbuf_N2O_37', 'pbuf_N2O_38', 'pbuf_N2O_39', 'pbuf_N2O_40', 'pbuf_N2O_41', 'pbuf_N2O_42', 'pbuf_N2O_43', 'pbuf_N2O_44', 'pbuf_N2O_45', 'pbuf_N2O_46', 'pbuf_N2O_47', 'pbuf_N2O_48', 'pbuf_N2O_49', 'pbuf_N2O_50', 'pbuf_N2O_51', 'pbuf_N2O_52', 'pbuf_N2O_53', 'pbuf_N2O_54', 'pbuf_N2O_55', 'pbuf_N2O_56', 'pbuf_N2O_57', 'pbuf_N2O_58', 'pbuf_N2O_59',\"state_ps\",\"pbuf_SOLIN\",\"pbuf_LHFLX\",\"pbuf_SHFLX\",\"pbuf_TAUX\",\"pbuf_TAUY\",\"pbuf_COSZRS\",\"cam_in_ALDIF\",\"cam_in_ALDIR\",\"cam_in_ASDIF\",\"cam_in_ASDIR\",\"cam_in_LWUP\",\"cam_in_ICEFRAC\",\"cam_in_LANDFRAC\",\"cam_in_OCNFRAC\",\"cam_in_SNOWHLAND\"]\n","TARGET_NAMES = ['ptend_t_0', 'ptend_t_1', 'ptend_t_2', 'ptend_t_3', 'ptend_t_4', 'ptend_t_5', 'ptend_t_6', 'ptend_t_7', 'ptend_t_8', 'ptend_t_9', 'ptend_t_10', 'ptend_t_11', 'ptend_t_12', 'ptend_t_13', 'ptend_t_14', 'ptend_t_15', 'ptend_t_16', 'ptend_t_17', 'ptend_t_18', 'ptend_t_19', 'ptend_t_20', 'ptend_t_21', 'ptend_t_22', 'ptend_t_23', 'ptend_t_24', 'ptend_t_25', 'ptend_t_26', 'ptend_t_27', 'ptend_t_28', 'ptend_t_29', 'ptend_t_30', 'ptend_t_31', 'ptend_t_32', 'ptend_t_33', 'ptend_t_34', 'ptend_t_35', 'ptend_t_36', 'ptend_t_37', 'ptend_t_38', 'ptend_t_39', 'ptend_t_40', 'ptend_t_41', 'ptend_t_42', 'ptend_t_43', 'ptend_t_44', 'ptend_t_45', 'ptend_t_46', 'ptend_t_47', 'ptend_t_48', 'ptend_t_49', 'ptend_t_50', 'ptend_t_51', 'ptend_t_52', 'ptend_t_53', 'ptend_t_54', 'ptend_t_55', 'ptend_t_56', 'ptend_t_57', 'ptend_t_58', 'ptend_t_59', 'ptend_q0001_0', 'ptend_q0001_1', 'ptend_q0001_2', 'ptend_q0001_3', 'ptend_q0001_4', 'ptend_q0001_5', 'ptend_q0001_6', 'ptend_q0001_7', 'ptend_q0001_8', 'ptend_q0001_9', 'ptend_q0001_10', 'ptend_q0001_11', 'ptend_q0001_12', 'ptend_q0001_13', 'ptend_q0001_14', 'ptend_q0001_15', 'ptend_q0001_16', 'ptend_q0001_17', 'ptend_q0001_18', 'ptend_q0001_19', 'ptend_q0001_20', 'ptend_q0001_21', 'ptend_q0001_22', 'ptend_q0001_23', 'ptend_q0001_24', 'ptend_q0001_25', 'ptend_q0001_26', 'ptend_q0001_27', 'ptend_q0001_28', 'ptend_q0001_29', 'ptend_q0001_30', 'ptend_q0001_31', 'ptend_q0001_32', 'ptend_q0001_33', 'ptend_q0001_34', 'ptend_q0001_35', 'ptend_q0001_36', 'ptend_q0001_37', 'ptend_q0001_38', 'ptend_q0001_39', 'ptend_q0001_40', 'ptend_q0001_41', 'ptend_q0001_42', 'ptend_q0001_43', 'ptend_q0001_44', 'ptend_q0001_45', 'ptend_q0001_46', 'ptend_q0001_47', 'ptend_q0001_48', 'ptend_q0001_49', 'ptend_q0001_50', 'ptend_q0001_51', 'ptend_q0001_52', 'ptend_q0001_53', 'ptend_q0001_54', 'ptend_q0001_55', 'ptend_q0001_56', 'ptend_q0001_57', 'ptend_q0001_58', 'ptend_q0001_59', 'ptend_q0002_0', 'ptend_q0002_1', 'ptend_q0002_2', 'ptend_q0002_3', 'ptend_q0002_4', 'ptend_q0002_5', 'ptend_q0002_6', 'ptend_q0002_7', 'ptend_q0002_8', 'ptend_q0002_9', 'ptend_q0002_10', 'ptend_q0002_11', 'ptend_q0002_12', 'ptend_q0002_13', 'ptend_q0002_14', 'ptend_q0002_15', 'ptend_q0002_16', 'ptend_q0002_17', 'ptend_q0002_18', 'ptend_q0002_19', 'ptend_q0002_20', 'ptend_q0002_21', 'ptend_q0002_22', 'ptend_q0002_23', 'ptend_q0002_24', 'ptend_q0002_25', 'ptend_q0002_26', 'ptend_q0002_27', 'ptend_q0002_28', 'ptend_q0002_29', 'ptend_q0002_30', 'ptend_q0002_31', 'ptend_q0002_32', 'ptend_q0002_33', 'ptend_q0002_34', 'ptend_q0002_35', 'ptend_q0002_36', 'ptend_q0002_37', 'ptend_q0002_38', 'ptend_q0002_39', 'ptend_q0002_40', 'ptend_q0002_41', 'ptend_q0002_42', 'ptend_q0002_43', 'ptend_q0002_44', 'ptend_q0002_45', 'ptend_q0002_46', 'ptend_q0002_47', 'ptend_q0002_48', 'ptend_q0002_49', 'ptend_q0002_50', 'ptend_q0002_51', 'ptend_q0002_52', 'ptend_q0002_53', 'ptend_q0002_54', 'ptend_q0002_55', 'ptend_q0002_56', 'ptend_q0002_57', 'ptend_q0002_58', 'ptend_q0002_59', 'ptend_q0003_0', 'ptend_q0003_1', 'ptend_q0003_2', 'ptend_q0003_3', 'ptend_q0003_4', 'ptend_q0003_5', 'ptend_q0003_6', 'ptend_q0003_7', 'ptend_q0003_8', 'ptend_q0003_9', 'ptend_q0003_10', 'ptend_q0003_11', 'ptend_q0003_12', 'ptend_q0003_13', 'ptend_q0003_14', 'ptend_q0003_15', 'ptend_q0003_16', 'ptend_q0003_17', 'ptend_q0003_18', 'ptend_q0003_19', 'ptend_q0003_20', 'ptend_q0003_21', 'ptend_q0003_22', 'ptend_q0003_23', 'ptend_q0003_24', 'ptend_q0003_25', 'ptend_q0003_26', 'ptend_q0003_27', 'ptend_q0003_28', 'ptend_q0003_29', 'ptend_q0003_30', 'ptend_q0003_31', 'ptend_q0003_32', 'ptend_q0003_33', 'ptend_q0003_34', 'ptend_q0003_35', 'ptend_q0003_36', 'ptend_q0003_37', 'ptend_q0003_38', 'ptend_q0003_39', 'ptend_q0003_40', 'ptend_q0003_41', 'ptend_q0003_42', 'ptend_q0003_43', 'ptend_q0003_44', 'ptend_q0003_45', 'ptend_q0003_46', 'ptend_q0003_47', 'ptend_q0003_48', 'ptend_q0003_49', 'ptend_q0003_50', 'ptend_q0003_51', 'ptend_q0003_52', 'ptend_q0003_53', 'ptend_q0003_54', 'ptend_q0003_55', 'ptend_q0003_56', 'ptend_q0003_57', 'ptend_q0003_58', 'ptend_q0003_59', 'ptend_u_0', 'ptend_u_1', 'ptend_u_2', 'ptend_u_3', 'ptend_u_4', 'ptend_u_5', 'ptend_u_6', 'ptend_u_7', 'ptend_u_8', 'ptend_u_9', 'ptend_u_10', 'ptend_u_11', 'ptend_u_12', 'ptend_u_13', 'ptend_u_14', 'ptend_u_15', 'ptend_u_16', 'ptend_u_17', 'ptend_u_18', 'ptend_u_19', 'ptend_u_20', 'ptend_u_21', 'ptend_u_22', 'ptend_u_23', 'ptend_u_24', 'ptend_u_25', 'ptend_u_26', 'ptend_u_27', 'ptend_u_28', 'ptend_u_29', 'ptend_u_30', 'ptend_u_31', 'ptend_u_32', 'ptend_u_33', 'ptend_u_34', 'ptend_u_35', 'ptend_u_36', 'ptend_u_37', 'ptend_u_38', 'ptend_u_39', 'ptend_u_40', 'ptend_u_41', 'ptend_u_42', 'ptend_u_43', 'ptend_u_44', 'ptend_u_45', 'ptend_u_46', 'ptend_u_47', 'ptend_u_48', 'ptend_u_49', 'ptend_u_50', 'ptend_u_51', 'ptend_u_52', 'ptend_u_53', 'ptend_u_54', 'ptend_u_55', 'ptend_u_56', 'ptend_u_57', 'ptend_u_58', 'ptend_u_59', 'ptend_v_0', 'ptend_v_1', 'ptend_v_2', 'ptend_v_3', 'ptend_v_4', 'ptend_v_5', 'ptend_v_6', 'ptend_v_7', 'ptend_v_8', 'ptend_v_9', 'ptend_v_10', 'ptend_v_11', 'ptend_v_12', 'ptend_v_13', 'ptend_v_14', 'ptend_v_15', 'ptend_v_16', 'ptend_v_17', 'ptend_v_18', 'ptend_v_19', 'ptend_v_20', 'ptend_v_21', 'ptend_v_22', 'ptend_v_23', 'ptend_v_24', 'ptend_v_25', 'ptend_v_26', 'ptend_v_27', 'ptend_v_28', 'ptend_v_29', 'ptend_v_30', 'ptend_v_31', 'ptend_v_32', 'ptend_v_33', 'ptend_v_34', 'ptend_v_35', 'ptend_v_36', 'ptend_v_37', 'ptend_v_38', 'ptend_v_39', 'ptend_v_40', 'ptend_v_41', 'ptend_v_42', 'ptend_v_43', 'ptend_v_44', 'ptend_v_45', 'ptend_v_46', 'ptend_v_47', 'ptend_v_48', 'ptend_v_49', 'ptend_v_50', 'ptend_v_51', 'ptend_v_52', 'ptend_v_53', 'ptend_v_54', 'ptend_v_55', 'ptend_v_56', 'ptend_v_57', 'ptend_v_58', 'ptend_v_59', 'cam_out_NETSW', 'cam_out_FLWDS', 'cam_out_PRECSC', 'cam_out_PRECC', 'cam_out_SOLS', 'cam_out_SOLL', 'cam_out_SOLSD', 'cam_out_SOLLD']"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["368"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["len(TARGET_WEIGHTS)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.474614Z","iopub.status.busy":"2024-06-03T13:32:49.474304Z","iopub.status.idle":"2024-06-03T13:32:49.515197Z","shell.execute_reply":"2024-06-03T13:32:49.514132Z","shell.execute_reply.started":"2024-06-03T13:32:49.474590Z"},"trusted":true},"outputs":[],"source":["ID_IDX = 0\n","\n","STATE_PS_IDX = 360\n","\n","PBUF_SOLIN_IDX = 361\n","PBUF_LHFLX_IDX = 362\n","PBUF_SHFLX_IDX = 363\n","PBUF_TAUX_IDX = 364\n","PBUF_TAUY_IDX = 365\n","PBUF_COSZRS_IDX = 366\n","\n","CAM_IN_ALDIF_IDX = 367\n","CAM_IN_ALDIR_IDX = 368\n","CAM_IN_ASDIF_IDX = 369\n","CAM_IN_ASDIR_IDX = 370\n","CAM_IN_LWUP_IDX = 371\n","CAM_IN_ICEFRAC_IDX = 372\n","CAM_IN_LANDFRAC_IDX = 373\n","CAM_IN_OCNFRAC_IDX = 374\n","CAM_IN_SNOWHLAND_IDX = 375\n","\n","CAM_OUT_NETSW_IDX = 360\n","CAM_OUT_FLWDS_IDX = 361\n","CAM_OUT_PRECSC_IDX = 362\n","CAM_OUT_PRECC_IDX = 363\n","CAM_OUT_SOLS_IDX = 364\n","CAM_OUT_SOLL_IDX = 365\n","CAM_OUT_SOLSD_IDX = 366\n","CAM_OUT_SOLLD_IDX = 367\n","\n","STATE_U_IDX = [240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299]\n","STATE_V_IDX = [300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359]\n","STATE_T_IDX = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n","\n","STATE_Q0001_IDX = [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]\n","STATE_Q0002_IDX = [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n","STATE_Q0003_IDX = [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]\n","\n","PBUF_OZONE_IDX = [376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435]\n","PBUF_CH4_IDX = [436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495]\n","PBUF_N2O_IDX = [496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555]\n","\n","PTEND_Q0001_IDX = [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]\n","PTEND_Q0002_IDX = [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n","PTEND_Q0003_IDX = [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]\n","\n","PTEND_U_IDX = [240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299]\n","PTEND_V_IDX = [300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359]\n","PTEND_T_IDX = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import numpy as np\n","column_indices = list(range(DIM_FEATURES))\n","\n","front_indices = column_indices[:-16]\n","back_indices = column_indices[-16:]\n","repeated_back_indices = np.repeat(back_indices, 60)\n","\n","final_indices = front_indices + list(repeated_back_indices)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.517300Z","iopub.status.busy":"2024-06-03T13:32:49.516912Z","iopub.status.idle":"2024-06-03T13:32:49.530328Z","shell.execute_reply":"2024-06-03T13:32:49.529409Z","shell.execute_reply.started":"2024-06-03T13:32:49.517267Z"},"trusted":true},"outputs":[],"source":["def r2_score(y_pred:torch.Tensor, y_true:torch.Tensor) -> float:\n","    \n","    ss_res = torch.sum((y_true - y_pred) ** 2)\n","    ss_tot = torch.sum((y_true - torch.mean(y_true)) ** 2)\n","    \n","    r2 = 1 - ss_res / ss_tot\n","    \n","    return r2.item()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.532320Z","iopub.status.busy":"2024-06-03T13:32:49.531966Z","iopub.status.idle":"2024-06-03T13:32:49.539755Z","shell.execute_reply":"2024-06-03T13:32:49.538814Z","shell.execute_reply.started":"2024-06-03T13:32:49.532290Z"},"trusted":true},"outputs":[],"source":["def calc_mean_std(ds_data:Dataset) -> None:\n","    \n","    global X_MEAN, X_STD, Y_MEAN, Y_STD\n","    \n","    x = ds_data.x\n","    y = ds_data.y\n","    \n","    X_MEAN = torch.mean(x, 0)\n","    X_STD = torch.maximum(torch.std(x, 0), torch.tensor(ERR))\n","    \n","    Y_MEAN = y.mean(axis=0)\n","    Y_STD = torch.maximum(torch.sqrt(torch.mean(torch.pow(y, 2), 0)), torch.tensor(ERR))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.541089Z","iopub.status.busy":"2024-06-03T13:32:49.540834Z","iopub.status.idle":"2024-06-03T13:32:49.550388Z","shell.execute_reply":"2024-06-03T13:32:49.549388Z","shell.execute_reply.started":"2024-06-03T13:32:49.541067Z"},"trusted":true},"outputs":[],"source":["import random\n","def train_fn(\n","    model: nn.Module, \n","    loader: DataLoader, \n","    optimizer: optim.Optimizer, \n","    criterion: nn.Module,\n",") -> float:\n","    \n","    progress_bar = tqdm(enumerate(loader, start=1), total=len(loader), ncols=100)\n","    progress_bar.set_description(f'Epoch {epoch}')\n","    model.train()\n","    train_loss = 0\n","    \n","    for step, batch in progress_bar:\n","        x, y = batch\n","        x, y = x.to(DEVICE), y.to(DEVICE)\n","        \n","        optimizer.zero_grad()\n","        y_pred = model(x)\n","        \n","        # random_number = random.uniform(0, 2)\n","        # criterion = nn.HuberLoss(delta=random_number)\n","        loss = criterion(y_pred, y)\n","        \n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","        progress_bar.set_postfix({\n","            'train_loss': train_loss / step,\n","        })\n","        \n","    return train_loss"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.551924Z","iopub.status.busy":"2024-06-03T13:32:49.551569Z","iopub.status.idle":"2024-06-03T13:32:49.564043Z","shell.execute_reply":"2024-06-03T13:32:49.563017Z","shell.execute_reply.started":"2024-06-03T13:32:49.551901Z"},"trusted":true},"outputs":[],"source":["def valid_fn(model: nn.Module, loader: DataLoader) -> float:\n","   \n","    progress_bar = tqdm(enumerate(loader, start=1), total=len(loader), ncols=100)\n","    progress_bar.set_description(f'Epoch {epoch}')\n","    model.eval()\n","    val_score = 0\n","    \n","    with torch.no_grad():\n","        for step, batch in progress_bar:\n","            x, y = batch\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            \n","            y_pred = model(x)\n","            \n","            y = y.cpu()\n","           \n","            y = (y * Y_STD) + Y_MEAN\n","            \n","            \n","            y_pred = y_pred.cpu()\n","                \n","            y_pred[:, Y_STD < (1.1 * ERR)] = 0\n","            y_pred = (y_pred * Y_STD) + Y_MEAN\n","            \n","            val_score += r2_score(y_pred, y)\n","            \n","            progress_bar.set_postfix({\n","                'valid_score': val_score / step,\n","            })\n","            \n","    return val_score/step"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.565369Z","iopub.status.busy":"2024-06-03T13:32:49.565047Z","iopub.status.idle":"2024-06-03T13:32:49.575875Z","shell.execute_reply":"2024-06-03T13:32:49.574943Z","shell.execute_reply.started":"2024-06-03T13:32:49.565346Z"},"trusted":true},"outputs":[],"source":["def pred_fn(model: nn.Module, df_test: pl.DataFrame):\n","    model.eval()\n","\n","    x_test = df_test[FEATURE_NAMES]\n","    x_test = x_test.to_numpy()\n","\n","    x_test = x_test[:,final_indices]\n","\n","    x_test = torch.from_numpy(x_test)\n","    \n","    x_test = (x_test - X_MEAN) / X_STD\n","    \n","    x_test = x_test.to(torch.float32)\n","    x_test = x_test.to(DEVICE)\n","    y_pred = []\n","    with torch.no_grad():\n","        start = 0\n","        end = BATCH_SIZE\n","        while start<x_test.shape[0]:\n","            x_input = x_test[start:end]\n","            y = model(x_input)\n","            start = end\n","            end = end + BATCH_SIZE\n","            y_pred.append(y)\n","    y_pred = torch.cat(y_pred,dim=0)\n","        \n","    y_pred = y_pred.cpu()\n","    y_pred = y_pred.to(torch.float64)\n","    \n","    \n","    y_pred[:, Y_STD < (1.1 * ERR)] = 0\n","    y_pred = (y_pred * Y_STD) + Y_MEAN\n","    \n","    \n","    y_pred = y_pred.detach()\n","    y_pred = y_pred.cpu()\n","    y_pred = y_pred.numpy()\n","    \n","    return y_pred"]},{"cell_type":"markdown","metadata":{},"source":["### LeapDataset Class for Handling CSV Data in PyTorch"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.577511Z","iopub.status.busy":"2024-06-03T13:32:49.577154Z","iopub.status.idle":"2024-06-03T13:32:49.589762Z","shell.execute_reply":"2024-06-03T13:32:49.588577Z","shell.execute_reply.started":"2024-06-03T13:32:49.577478Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, TensorDataset\n","class LeapDataset(Dataset):\n","    def __init__(self, file_path, x_features, y_features, y_weights):        \n","        super().__init__()\n","        global X_MEAN, X_STD, Y_MEAN, Y_STD\n","        # data = pl.read_parquet(file_path)\n","        data = pl.read_csv(file_path)\n","        \n","        self.x = pl.DataFrame()\n","\n","      \n","        \n","        self.x = data[x_features]\n","        self.x = self.x.to_numpy()\n","        self.x = self.x[:,final_indices]\n","        # last_16_columns = self.x[:, -16:]\n","        # replicated_columns = np.repeat(last_16_columns, 60, axis=1)\n","        # self.x = np.hstack((self.x[:, :-16], replicated_columns))\n","\n","        self.x = torch.from_numpy(self.x)\n","        \n","        self.y = data[y_features]\n","        self.y = self.y.to_numpy()\n","        self.y = torch.from_numpy(self.y)\n","        \n","        self.y = self.y * y_weights\n","\n","        X_MEAN = torch.mean(self.x, 0)\n","        X_STD = torch.maximum(torch.std(self.x, 0), torch.tensor(ERR))\n","        Y_MEAN = self.y.mean(axis=0)\n","        Y_STD = torch.maximum(torch.std(self.y, 0), torch.tensor(ERR))\n","        self.x = (self.x - X_MEAN) / X_STD\n","        self.y = (self.y - Y_MEAN) / Y_STD\n","        self.x = self.x.to(torch.float32)\n","        self.y = self.y.to(torch.float32)\n","    \n","        self.dataset = TensorDataset(self.x, self.y)\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n","    \n","    def __len__(self):\n","        return len(self.dataset)"]},{"cell_type":"markdown","metadata":{},"source":["### Custom Model"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class Uout(nn.Module):\n","    def __init__(self, p=0.1):\n","        super(Uout, self).__init__()\n","        self.beta = p\n","        \n","    def forward(self, x):\n","        if self.training:\n","            epsilon = (torch.rand_like(x) - 0.5) * 2 * self.beta\n","            epsilon = epsilon + 1\n","            return x * epsilon\n","        else:\n","            return x\n","DROP_RATE = 0.1\n","\n","\n","    \n","def conv3x1(in_planes, out_planes, stride=1,kernel = 3):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv1d(in_planes, out_planes, kernel_size=kernel, stride=stride,\n","                     padding=(kernel-1)//2, bias=False)\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv1d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","class spatial_attention_module(nn.Module):\n","    def __init__(self):\n","        super(spatial_attention_module, self).__init__()\n","        self.conv1d = nn.Conv1d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        avg_pool_out = torch.mean(x, dim=1, keepdim=True)\n","        out = torch.cat([avg_pool_out, max_out], dim=1)\n","        out = self.sigmoid(self.conv1d(out))\n","        return out\n","    \n","class channel_attention_module(nn.Module):\n","    def __init__(self, channel, reductio_ratio=2):\n","        super(channel_attention_module, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n","        self.max_pool = nn.AdaptiveMaxPool1d(1)\n","        self.MLP = nn.Sequential(\n","            nn.Conv1d(channel, channel // reductio_ratio,1 , bias=False),\n","            nn.LeakyReLU(),\n","            nn.Conv1d(channel // reductio_ratio, channel, 1, bias=False)\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_pool_out = self.MLP(self.avg_pool(x))\n","        max_pool_out = self.MLP(self.max_pool(x))\n","        return self.sigmoid(avg_pool_out + max_pool_out)\n","    \n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None,kernel =3):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x1(inplanes, planes, stride,kernel=kernel)\n","        self.bn1 = nn.BatchNorm1d(planes)\n","        self.relu = nn.LeakyReLU(inplace=True)\n","        self.conv2 = conv3x1(planes, planes,kernel=3)\n","        self.bn2 = nn.BatchNorm1d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","        self.channel = channel_attention_module(planes)\n","        self.spatial = spatial_attention_module()\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        \n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        c_out = self.channel(out)\n","        out = out * c_out\n","        s_out = self.spatial(out)\n","        out = out * s_out\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, in_channel=1, out_channel=10, zero_init_residual=True):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 32\n","        channel =32\n","        self.conv1 = nn.Conv1d(25, channel, kernel_size=3, stride=1, padding=1,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm1d(channel)\n","        self.relu = nn.LeakyReLU(inplace=True)\n","       \n","        self.layer1 = self._make_layer(block, channel, layers[0],kernel=5)\n","        self.layer2 = self._make_layer(block, channel*2, layers[1], stride=1,kernel=7)\n","        self.layer3 = self._make_layer(block, channel*4, layers[2], stride=1,kernel=9)\n","        self.layer4 = self._make_layer(block, channel*8, layers[3], stride=1,kernel=3)\n","        \n","        # 5,7,9,3\n","\n","        \n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1,kernel=3):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                nn.BatchNorm1d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample,kernel))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        \n","\n","       \n","\n","        return x\n","\n","\n","def resnet(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-18 model.\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(BasicBlock, [3,4,6,3], **kwargs)\n","    return model\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import torch\n","import torch\n","import math\n","import torchvision.models as models\n","import torchvision.models as models\n","\n","      \n","       \n","    \n","\n","class LeapModel(nn.Module):\n","    def __init__(self, num_input,num_heads,num_layers,num_labels,dropout_rate=0.5):\n","        \"\"\"\n","        Initializes the LeapModel.\n","\n","        Parameters\n","        ----------\n","        dims : list of int\n","            A list containing the dimensions of each layer in the network. \n","            The length of the list determines the number of layers.\n","        \"\"\"\n","        \n","        super().__init__()\n","        \n","        \n","        self.resnet = resnet()\n","        self.cov = nn.Sequential(\n","            nn.Conv1d(256, 14, kernel_size=3, stride=1, padding=1,bias=False),\n","           \n","            )\n","        \n","        self.pool = nn.AdaptiveAvgPool1d(1)\n","        \n","\n","       \n","      \n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), 25,60)\n","        \n","        x = self.resnet(x)\n","        x = self.cov(x)\n","       \n","        front_part = x[:, :6, :]  \n","        back_part = x[:, 6:, :]   \n","        front_part_reshaped = front_part.view(front_part.size(0), -1)  \n","        back_part_mean = self.pool(back_part)\n","        back_part_mean = back_part_mean.view(back_part_mean.shape[0],-1)  \n","        result = torch.cat((front_part_reshaped, back_part_mean), dim=-1)  \n","       \n","        return result\n","        \n","\n","                \n","\n","    \n","        "]},{"cell_type":"markdown","metadata":{},"source":["### Creating Data Loaders for Training and Validation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:32:49.607157Z","iopub.status.busy":"2024-06-03T13:32:49.606715Z","iopub.status.idle":"2024-06-03T13:33:24.435896Z","shell.execute_reply":"2024-06-03T13:33:24.435095Z","shell.execute_reply.started":"2024-06-03T13:32:49.607123Z"},"trusted":true},"outputs":[],"source":["ds_data = LeapDataset(\n","    file_path=TRAIN_PATH,\n","    x_features=FEATURE_NAMES, \n","    y_features=TARGET_NAMES,\n","    y_weights=torch.tensor(TARGET_WEIGHTS),\n",")\n","\n","ds_train, ds_valid = random_split(ds_data, [TRAIN_SIZE, VALID_SIZE])\n","\n","train_loader = DataLoader(\n","    ds_train, \n","    batch_size=BATCH_SIZE, \n","    shuffle=True, \n","    num_workers=2,\n","    drop_last=True,\n",")\n","\n","valid_loader = DataLoader(\n","    ds_valid, \n","    batch_size=BATCH_SIZE, \n","    shuffle=False, \n","    drop_last=False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Mean and Standard Deviation Calculation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["num_heads = 4\n","num_layers = 4"]},{"cell_type":"markdown","metadata":{},"source":["### Exploratory Data Analysis"]},{"cell_type":"markdown","metadata":{},"source":["### Training"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["class LogCoshLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, y_prime_t, y_t):\n","        ey_t = (y_t - y_prime_t)/20 # divide by 3 to avoid numerical overflow in cosh\n","        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["class WarmupThenCosineAnnealingLR(torch.optim.lr_scheduler._LRScheduler):\n","    def __init__(self, optimizer, warmup_epochs, total_epochs, min_lr, last_epoch=-1):\n","        self.warmup_epochs = warmup_epochs\n","        self.total_epochs = total_epochs\n","        self.min_lr = min_lr\n","        self.cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n","            optimizer, T_max=total_epochs - warmup_epochs, eta_min=min_lr, last_epoch=last_epoch - warmup_epochs if last_epoch != -1 else last_epoch\n","        )\n","        super().__init__(optimizer, last_epoch)\n","\n","    def get_lr(self):\n","        if self.last_epoch < self.warmup_epochs:\n","            # Warmup phase: scale learning rate from 0 to base_lr linearly\n","            return [(base_lr - self.min_lr) * self.last_epoch / self.warmup_epochs + self.min_lr for base_lr in self.base_lrs]\n","        else:\n","            # Cosine annealing phase\n","            return self.cosine_scheduler.get_lr()\n","\n","    def step(self, epoch=None):\n","        if epoch is None:\n","            epoch = self.last_epoch + 1\n","        self.last_epoch = epoch\n","        if epoch >= self.warmup_epochs:\n","            self.cosine_scheduler.step(epoch - self.warmup_epochs)\n","        else:\n","            super().step(epoch)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:35:09.261451Z","iopub.status.busy":"2024-06-03T13:35:09.261093Z","iopub.status.idle":"2024-06-03T13:35:12.041841Z","shell.execute_reply":"2024-06-03T13:35:12.040943Z","shell.execute_reply.started":"2024-06-03T13:35:09.261420Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ycw/miniconda3/envs/gmmca/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"]},{"data":{"text/plain":["<torch._C.Generator at 0x7fe4b04be770>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["from lion_pytorch import Lion\n","model = LeapModel(DIM_FEATURES, num_heads,num_layers,DIM_TARGETS)\n","model = model.to(DEVICE)\n","model.load_state_dict(torch.load(\"0.733.pth\", map_location=DEVICE))\n","\n","\n","criterion1 = nn.MSELoss()\n","# criterion = LogCoshLoss()\n","criterion2 = nn.MSELoss()\n","criterion3 = nn.L1Loss()\n","criterion = nn.MSELoss()\n","optimizer = Lion(model.parameters(), lr=LEARNING_RATE,weight_decay=1e-2)\n","# import adabound\n","\n","LEARNING_RATE=1e-6\n","NUM_EPOCHS = 4\n","# optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","\n","scheduler = WarmupThenCosineAnnealingLR(optimizer,warmup_epochs=3,total_epochs=NUM_EPOCHS,min_lr=LEARNING_RATE/100)\n","#scheduler = lr_scheduler.PolynomialLR(optimizer, power=1.0, total_iters=NUM_EPOCHS)\n","# scheduler=lr_scheduler.CosineAnnealingLR(optimizer,T_max=NUM_EPOCHS,eta_min=LEARNING_RATE/100)\n","# for i in range(10):\n","#     scheduler.step()\n","\n","torch.manual_seed(111)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["from sklearn.metrics import r2_score\n","def valid(model: nn.Module, loader: DataLoader) -> float:\n","   \n","    progress_bar = tqdm(enumerate(loader, start=1), total=len(loader), ncols=100)\n","    progress_bar.set_description(f'Epoch {epoch}')\n","    model.eval()\n","    val_score = 0\n","    Y = []\n","    Y_pred = []\n","    with torch.no_grad():\n","        for step, batch in progress_bar:\n","            x, y = batch\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            \n","            y_pred = model(x)\n","            \n","            y = y.cpu()\n","            y_pred = y_pred.cpu()  \n","            # print(y)\n","            # print(y_pred)\n","            Y.append(y)\n","            Y_pred.append(y_pred)\n","            \n","           \n","            \n","            progress_bar.set_postfix({\n","                'valid_score': 'wait',\n","            })\n","    Y = torch.cat(Y,dim=0)\n","    Y_pred = torch.cat(Y_pred,dim=0)\n","    Y = (Y * Y_STD) + Y_MEAN        \n","    Y_pred[:, Y_STD < (1.1 * ERR)] = 0\n","    Y_pred = (Y_pred * Y_STD) + Y_MEAN   \n","    val_score = r2_score(Y,Y_pred,multioutput='raw_values')   \n","    return val_score"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 0: 100%|| 63215/63215 [28:16<00:00, 37.27it/s, valid_score=wait]\n"]},{"ename":"AssertionError","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m val_score \u001b[38;5;241m=\u001b[39m valid(model, train_loader)\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39mmean(val_score)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m\n","\u001b[0;31mAssertionError\u001b[0m: "]}],"source":["epoch = 0 \n","val_score = valid(model, train_loader)\n","np.mean(val_score)\n","assert 1==0"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.7362230047784877\n"]}],"source":["print(np.mean(val_score))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T13:35:19.286153Z","iopub.status.busy":"2024-06-03T13:35:19.285141Z","iopub.status.idle":"2024-06-03T13:42:08.337353Z","shell.execute_reply":"2024-06-03T13:42:08.335705Z","shell.execute_reply.started":"2024-06-03T13:35:19.286115Z"},"trusted":true},"outputs":[],"source":["# best_score = -np.inf\n","# patience = 100\n","# counter = 0\n","# for epoch in range(NUM_EPOCHS):\n","#     train_loss = train_fn(model, train_loader, optimizer, criterion)\n","#     val_score = valid_fn(model, valid_loader)\n","#     if val_score >= best_score:\n","#         best_score = val_score\n","#         torch.save(model.state_dict(), \"best_.pth\")\n","#         counter = 0\n","#     else:\n","#         counter = counter +1\n","#         if counter>=patience:\n","#             print('early stop')\n","#             break\n","#     scheduler.step()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-03T13:42:08.338087Z","iopub.status.idle":"2024-06-03T13:42:08.338420Z","shell.execute_reply":"2024-06-03T13:42:08.338273Z","shell.execute_reply.started":"2024-06-03T13:42:08.338259Z"},"trusted":true},"outputs":[],"source":["model = LeapModel(DIM_FEATURES, num_heads, num_layers, DIM_TARGETS)\n","model = model.to(DEVICE)\n","model.load_state_dict(torch.load(\"0.733.pth\", map_location=DEVICE))\n","\n","df_test = pl.read_csv(TEST_PATH)\n","df_test = df_test.to_pandas()\n","df_test = df_test.set_index(\"sample_id\")\n","\n","df_subm = pl.read_csv(SUBMISSION_PATH)\n","df_subm = df_subm.to_pandas()\n","df_subm = df_subm.set_index(\"sample_id\")\n","\n","static_pred = -df_test[REPLACE_TO].to_numpy() * df_subm[REPLACE_FROM].to_numpy() / 1200"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-03T13:42:08.339748Z","iopub.status.idle":"2024-06-03T13:42:08.340142Z","shell.execute_reply":"2024-06-03T13:42:08.339986Z","shell.execute_reply.started":"2024-06-03T13:42:08.339970Z"},"trusted":true},"outputs":[],"source":["df_subm.loc[df_test.index, TARGET_NAMES] = pred_fn(model, df_test)\n","\n","df_subm[REPLACE_FROM] = static_pred\n","\n","df_subm = df_subm.reset_index()\n","df_subm = df_subm[[\"sample_id\"] + TARGET_NAMES]\n","df_subm = pl.from_pandas(df_subm)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","sample = pd.read_csv(SUBMISSION_PATH)\n","new_weights = sample[TARGET_NAMES].to_numpy().flatten()\n","\n","for w_new, w_old,t in zip(new_weights, TARGET_WEIGHTS, TARGET_NAMES):\n","    if w_new != 0:\n","        if w_old != 0:\n","            df_subm = df_subm.with_columns(\n","            (df_subm[t] / w_old).alias(t) \n","            )\n","            \n","    else:    \n","        df_subm = df_subm.with_columns(\n","        pl.lit(0.0).alias(t))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import polars as pl\n","data = pl.read_csv(TRAIN_PATH)        \n","y = data[TARGET_NAMES]\n","test = pl.read_csv(SUBMISSION_PATH)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (625_000, 369)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sample_id</th><th>ptend_t_0</th><th>ptend_t_1</th><th>ptend_t_2</th><th>ptend_t_3</th><th>ptend_t_4</th><th>ptend_t_5</th><th>ptend_t_6</th><th>ptend_t_7</th><th>ptend_t_8</th><th>ptend_t_9</th><th>ptend_t_10</th><th>ptend_t_11</th><th>ptend_t_12</th><th>ptend_t_13</th><th>ptend_t_14</th><th>ptend_t_15</th><th>ptend_t_16</th><th>ptend_t_17</th><th>ptend_t_18</th><th>ptend_t_19</th><th>ptend_t_20</th><th>ptend_t_21</th><th>ptend_t_22</th><th>ptend_t_23</th><th>ptend_t_24</th><th>ptend_t_25</th><th>ptend_t_26</th><th>ptend_t_27</th><th>ptend_t_28</th><th>ptend_t_29</th><th>ptend_t_30</th><th>ptend_t_31</th><th>ptend_t_32</th><th>ptend_t_33</th><th>ptend_t_34</th><th>ptend_t_35</th><th>&hellip;</th><th>ptend_v_31</th><th>ptend_v_32</th><th>ptend_v_33</th><th>ptend_v_34</th><th>ptend_v_35</th><th>ptend_v_36</th><th>ptend_v_37</th><th>ptend_v_38</th><th>ptend_v_39</th><th>ptend_v_40</th><th>ptend_v_41</th><th>ptend_v_42</th><th>ptend_v_43</th><th>ptend_v_44</th><th>ptend_v_45</th><th>ptend_v_46</th><th>ptend_v_47</th><th>ptend_v_48</th><th>ptend_v_49</th><th>ptend_v_50</th><th>ptend_v_51</th><th>ptend_v_52</th><th>ptend_v_53</th><th>ptend_v_54</th><th>ptend_v_55</th><th>ptend_v_56</th><th>ptend_v_57</th><th>ptend_v_58</th><th>ptend_v_59</th><th>cam_out_NETSW</th><th>cam_out_FLWDS</th><th>cam_out_PRECSC</th><th>cam_out_PRECC</th><th>cam_out_SOLS</th><th>cam_out_SOLL</th><th>cam_out_SOLSD</th><th>cam_out_SOLLD</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;test_0&quot;</td><td>0.000006</td><td>-0.000061</td><td>-0.000079</td><td>-0.000082</td><td>-0.000092</td><td>-0.000094</td><td>-0.000078</td><td>-0.000062</td><td>-0.000047</td><td>-0.000039</td><td>-0.000027</td><td>-0.000017</td><td>-0.000008</td><td>-0.000003</td><td>3.5914e-8</td><td>0.000002</td><td>0.000006</td><td>0.000004</td><td>0.000002</td><td>-0.000006</td><td>0.000007</td><td>-0.000003</td><td>-0.000012</td><td>-0.000016</td><td>-0.000015</td><td>-0.000012</td><td>-0.000015</td><td>-0.000017</td><td>-0.000021</td><td>-0.000028</td><td>-0.000036</td><td>-0.000032</td><td>-0.000023</td><td>-0.000019</td><td>-0.000018</td><td>-0.000016</td><td>&hellip;</td><td>4.1542e-7</td><td>0.000002</td><td>-2.3328e-7</td><td>-0.000002</td><td>-0.000001</td><td>-7.0200e-7</td><td>-6.2644e-7</td><td>-0.000003</td><td>-7.2478e-7</td><td>-5.9234e-7</td><td>3.3608e-8</td><td>-0.000003</td><td>0.000005</td><td>0.000001</td><td>0.000002</td><td>-0.000005</td><td>-0.000008</td><td>-0.000024</td><td>-0.000046</td><td>-0.000045</td><td>-0.000018</td><td>0.000033</td><td>0.000038</td><td>0.000041</td><td>0.000021</td><td>0.000013</td><td>0.000009</td><td>0.000006</td><td>6.1466e-7</td><td>-0.383395</td><td>397.388142</td><td>3.2604e-11</td><td>-2.7879e-9</td><td>0.587271</td><td>0.470669</td><td>-0.507998</td><td>0.400657</td></tr><tr><td>&quot;test_10&quot;</td><td>0.000002</td><td>-0.000026</td><td>-0.000015</td><td>-0.000036</td><td>-0.000078</td><td>-0.00012</td><td>-0.000122</td><td>-0.000085</td><td>-0.000037</td><td>-0.000018</td><td>-0.000013</td><td>-0.000011</td><td>-0.00001</td><td>-0.000008</td><td>-0.000006</td><td>-0.000005</td><td>-0.000004</td><td>-0.000003</td><td>-0.000001</td><td>-0.000005</td><td>-0.000004</td><td>-0.000007</td><td>-0.000007</td><td>-0.000007</td><td>-0.000008</td><td>-0.000011</td><td>-0.000013</td><td>-0.000017</td><td>-0.000018</td><td>-0.00002</td><td>-0.00002</td><td>-0.000016</td><td>-0.000011</td><td>-0.000003</td><td>-4.0443e-7</td><td>0.000002</td><td>&hellip;</td><td>-4.5267e-7</td><td>-4.0156e-7</td><td>3.3495e-7</td><td>4.5810e-7</td><td>3.6472e-7</td><td>2.5676e-7</td><td>2.3085e-7</td><td>1.4759e-7</td><td>-6.4173e-8</td><td>4.4971e-8</td><td>3.7528e-7</td><td>-0.000001</td><td>4.6093e-7</td><td>-4.4998e-7</td><td>0.000002</td><td>3.2108e-7</td><td>-5.2167e-7</td><td>-0.000002</td><td>-0.000002</td><td>-0.000002</td><td>-0.000003</td><td>-0.000001</td><td>1.6279e-7</td><td>0.000001</td><td>0.000003</td><td>0.000002</td><td>0.000001</td><td>-0.000001</td><td>0.000004</td><td>10.601492</td><td>334.870423</td><td>5.7478e-11</td><td>-3.2231e-10</td><td>4.560882</td><td>2.484528</td><td>2.899083</td><td>2.119797</td></tr><tr><td>&quot;test_100&quot;</td><td>0.000001</td><td>-0.000067</td><td>-0.000024</td><td>-0.000024</td><td>-0.000071</td><td>-0.000093</td><td>-0.000077</td><td>-0.000049</td><td>-0.000028</td><td>-0.000019</td><td>-0.000015</td><td>-0.000013</td><td>-0.000011</td><td>-0.000009</td><td>-0.000006</td><td>-0.000004</td><td>-0.000003</td><td>-0.000004</td><td>0.000004</td><td>-0.000009</td><td>-0.000004</td><td>-0.000007</td><td>-0.000006</td><td>-0.000006</td><td>-0.000004</td><td>-0.000004</td><td>-0.000007</td><td>-0.000005</td><td>-0.000006</td><td>-0.000011</td><td>-0.000014</td><td>-0.000017</td><td>-0.00002</td><td>-0.00002</td><td>-0.000023</td><td>-0.000024</td><td>&hellip;</td><td>-0.000002</td><td>-0.000002</td><td>-7.7685e-7</td><td>3.2854e-7</td><td>8.2988e-7</td><td>4.8305e-7</td><td>4.3648e-7</td><td>5.4116e-7</td><td>3.1635e-7</td><td>8.8304e-8</td><td>-2.9214e-7</td><td>-2.8616e-7</td><td>3.4695e-8</td><td>0.000002</td><td>8.7396e-7</td><td>-3.6196e-7</td><td>-0.000002</td><td>-0.000005</td><td>-0.00001</td><td>-0.00002</td><td>-0.000023</td><td>0.000008</td><td>0.00001</td><td>0.000013</td><td>0.000009</td><td>0.000002</td><td>0.000004</td><td>0.000003</td><td>0.000012</td><td>8.011045</td><td>327.582036</td><td>1.8015e-11</td><td>4.4917e-9</td><td>0.430553</td><td>0.54001</td><td>1.814647</td><td>1.376022</td></tr><tr><td>&quot;test_1000&quot;</td><td>0.000027</td><td>0.00001</td><td>0.000032</td><td>0.000028</td><td>-0.000008</td><td>-0.000052</td><td>-0.000044</td><td>-0.000021</td><td>-0.000006</td><td>-0.000002</td><td>-3.4139e-7</td><td>2.1442e-9</td><td>0.000001</td><td>0.000003</td><td>0.000004</td><td>0.000005</td><td>0.000006</td><td>0.000005</td><td>5.3782e-7</td><td>6.5935e-7</td><td>-1.2208e-7</td><td>-0.000001</td><td>-0.000009</td><td>-0.000018</td><td>-0.000016</td><td>-0.000013</td><td>-0.000015</td><td>-0.000017</td><td>-0.000021</td><td>-0.000023</td><td>-0.000021</td><td>-0.000021</td><td>-0.000018</td><td>-0.000017</td><td>-0.000016</td><td>-0.000016</td><td>&hellip;</td><td>1.6961e-9</td><td>-3.6256e-8</td><td>7.2284e-7</td><td>-0.000001</td><td>-2.6620e-8</td><td>0.000002</td><td>-0.000002</td><td>2.4478e-7</td><td>-9.7982e-7</td><td>4.2177e-7</td><td>-0.000003</td><td>0.000006</td><td>0.000003</td><td>0.000005</td><td>0.00001</td><td>0.000009</td><td>0.000008</td><td>0.00001</td><td>0.000008</td><td>0.000006</td><td>0.000006</td><td>0.000004</td><td>3.7408e-7</td><td>-0.000008</td><td>-0.000013</td><td>-0.000023</td><td>-0.000038</td><td>-0.000046</td><td>0.000027</td><td>4.040341</td><td>357.350264</td><td>3.5015e-11</td><td>2.0998e-9</td><td>-1.907318</td><td>5.347664</td><td>5.404898</td><td>0.65688</td></tr><tr><td>&quot;test_10000&quot;</td><td>0.000048</td><td>0.000026</td><td>0.000045</td><td>0.000085</td><td>0.000124</td><td>0.000174</td><td>0.000189</td><td>0.000147</td><td>0.000088</td><td>0.000062</td><td>0.000044</td><td>0.000035</td><td>0.000028</td><td>0.000019</td><td>0.000014</td><td>0.000011</td><td>0.000011</td><td>0.00001</td><td>0.000008</td><td>0.000006</td><td>0.000003</td><td>7.5474e-8</td><td>-0.000003</td><td>-0.000006</td><td>-0.00001</td><td>-0.000012</td><td>-0.000007</td><td>-0.000005</td><td>-0.000004</td><td>-0.000003</td><td>-0.000003</td><td>-0.000004</td><td>-0.000006</td><td>-0.000005</td><td>0.000002</td><td>3.5198e-7</td><td>&hellip;</td><td>4.7352e-8</td><td>7.6939e-8</td><td>1.0423e-7</td><td>7.4223e-8</td><td>1.3454e-8</td><td>4.8909e-8</td><td>2.7731e-8</td><td>-5.7962e-8</td><td>-1.9916e-7</td><td>1.0272e-7</td><td>-1.1223e-7</td><td>-5.3022e-8</td><td>-1.1611e-7</td><td>-2.2008e-7</td><td>2.3183e-7</td><td>-4.0258e-8</td><td>-2.7363e-7</td><td>1.6265e-7</td><td>5.3130e-8</td><td>-1.5505e-7</td><td>1.8466e-7</td><td>2.6863e-7</td><td>-4.9842e-7</td><td>-0.000001</td><td>2.1940e-7</td><td>0.000001</td><td>-1.7046e-7</td><td>6.4940e-7</td><td>-0.000002</td><td>926.089563</td><td>372.916137</td><td>6.3593e-11</td><td>-2.0753e-10</td><td>443.558318</td><td>456.536974</td><td>49.490086</td><td>4.552832</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;test_99994&quot;</td><td>0.000052</td><td>-0.000012</td><td>0.000019</td><td>0.000098</td><td>0.000126</td><td>0.00016</td><td>0.000142</td><td>0.000105</td><td>0.000066</td><td>0.000048</td><td>0.000038</td><td>0.000032</td><td>0.000024</td><td>0.000018</td><td>0.000011</td><td>0.000009</td><td>0.000009</td><td>0.000004</td><td>0.000002</td><td>0.000006</td><td>0.000007</td><td>-0.000001</td><td>-0.000005</td><td>-0.000001</td><td>-0.000002</td><td>-0.000003</td><td>-0.000009</td><td>-0.000021</td><td>-0.00002</td><td>-0.000018</td><td>-0.000016</td><td>-0.000014</td><td>-0.000009</td><td>-0.000002</td><td>-0.000013</td><td>-0.000008</td><td>&hellip;</td><td>0.000011</td><td>-0.000011</td><td>-0.000012</td><td>-0.00002</td><td>-0.000005</td><td>-0.000002</td><td>-0.000005</td><td>-0.000011</td><td>-0.000018</td><td>-0.00002</td><td>-0.000018</td><td>-0.000013</td><td>-0.000014</td><td>-0.000019</td><td>-0.000024</td><td>-0.000017</td><td>0.000004</td><td>0.00001</td><td>0.000014</td><td>0.000048</td><td>0.000052</td><td>0.000045</td><td>0.000038</td><td>0.000027</td><td>0.000015</td><td>0.000005</td><td>0.000002</td><td>0.000002</td><td>0.000006</td><td>427.249057</td><td>396.851407</td><td>4.4519e-13</td><td>3.7356e-8</td><td>178.624755</td><td>193.12039</td><td>68.456994</td><td>29.110252</td></tr><tr><td>&quot;test_99995&quot;</td><td>0.000006</td><td>-0.000059</td><td>-0.000136</td><td>-0.000075</td><td>-0.000065</td><td>-0.000062</td><td>-0.000051</td><td>-0.000041</td><td>-0.000026</td><td>-0.000018</td><td>-0.000012</td><td>-0.000009</td><td>-0.000008</td><td>-0.000008</td><td>-0.000008</td><td>-0.000007</td><td>-0.000007</td><td>-0.000007</td><td>-0.000006</td><td>-0.000006</td><td>-0.000005</td><td>-0.000004</td><td>-0.000004</td><td>-0.000004</td><td>-0.000004</td><td>-0.000004</td><td>-0.000004</td><td>-0.000005</td><td>-0.000006</td><td>-0.000006</td><td>-0.000006</td><td>-0.000007</td><td>-0.000007</td><td>-0.000007</td><td>-0.000008</td><td>-0.000009</td><td>&hellip;</td><td>-3.5795e-8</td><td>7.2994e-9</td><td>2.3149e-8</td><td>2.5757e-8</td><td>4.6870e-8</td><td>2.6178e-8</td><td>5.6546e-8</td><td>-6.5036e-10</td><td>2.3678e-9</td><td>-1.9364e-8</td><td>-9.7366e-9</td><td>6.6870e-8</td><td>9.3123e-8</td><td>2.4060e-8</td><td>-3.3708e-8</td><td>3.7794e-8</td><td>1.3103e-7</td><td>-6.4873e-8</td><td>-1.7315e-7</td><td>-8.2143e-8</td><td>2.3283e-7</td><td>2.0321e-8</td><td>1.2850e-7</td><td>1.9731e-7</td><td>-8.5721e-8</td><td>0.000002</td><td>-0.000001</td><td>0.000003</td><td>-0.000004</td><td>-1.48995</td><td>128.122883</td><td>2.5634e-9</td><td>3.2854e-9</td><td>-0.71373</td><td>0.002402</td><td>-0.584252</td><td>0.280264</td></tr><tr><td>&quot;test_99996&quot;</td><td>0.000031</td><td>0.000006</td><td>0.000013</td><td>0.000021</td><td>0.000039</td><td>0.00006</td><td>0.000056</td><td>0.000042</td><td>0.000024</td><td>0.000016</td><td>0.000011</td><td>0.000007</td><td>0.000005</td><td>0.000005</td><td>0.000005</td><td>0.000005</td><td>0.000003</td><td>0.000002</td><td>0.000003</td><td>0.000001</td><td>2.2346e-7</td><td>3.0421e-7</td><td>-5.3960e-7</td><td>-9.6354e-7</td><td>-3.7817e-7</td><td>-4.0651e-7</td><td>4.1853e-7</td><td>-2.9684e-7</td><td>-0.000001</td><td>-0.000001</td><td>-0.000001</td><td>-0.000001</td><td>-0.000002</td><td>-0.000002</td><td>-0.000003</td><td>-0.000004</td><td>&hellip;</td><td>-2.0458e-8</td><td>3.1802e-9</td><td>3.7653e-8</td><td>6.8424e-8</td><td>6.3794e-8</td><td>4.7582e-8</td><td>1.9864e-8</td><td>-9.7067e-9</td><td>-1.8813e-8</td><td>-3.1179e-8</td><td>-1.0820e-7</td><td>-7.1723e-8</td><td>1.3050e-7</td><td>5.7256e-8</td><td>2.3133e-7</td><td>3.5186e-8</td><td>8.9988e-8</td><td>3.6928e-8</td><td>-2.0055e-8</td><td>-5.8986e-8</td><td>-9.0440e-8</td><td>-1.0623e-7</td><td>1.8405e-8</td><td>3.3700e-8</td><td>-6.1914e-8</td><td>8.0526e-8</td><td>-3.9113e-8</td><td>-6.1224e-7</td><td>-1.9768e-7</td><td>76.277159</td><td>182.980684</td><td>6.4787e-9</td><td>6.1867e-9</td><td>106.770638</td><td>161.321352</td><td>64.524485</td><td>20.796938</td></tr><tr><td>&quot;test_99997&quot;</td><td>-0.000009</td><td>-0.000006</td><td>-0.00003</td><td>-0.000051</td><td>-0.000079</td><td>-0.000109</td><td>-0.000096</td><td>-0.000067</td><td>-0.000043</td><td>-0.000036</td><td>-0.000028</td><td>-0.00002</td><td>-0.000013</td><td>-0.000009</td><td>-0.000002</td><td>0.000001</td><td>0.000004</td><td>0.000004</td><td>0.000001</td><td>4.6972e-7</td><td>-0.000005</td><td>-0.000007</td><td>-0.000009</td><td>-0.000015</td><td>-0.000018</td><td>-0.000023</td><td>-0.00003</td><td>-0.00003</td><td>-0.000027</td><td>-0.000024</td><td>-0.000025</td><td>-0.000025</td><td>-0.000024</td><td>-0.000026</td><td>-0.000027</td><td>-0.000027</td><td>&hellip;</td><td>-3.4754e-7</td><td>-9.9077e-7</td><td>-0.000001</td><td>-7.9622e-7</td><td>-1.5085e-7</td><td>-1.1935e-7</td><td>2.7211e-7</td><td>0.000004</td><td>-0.000007</td><td>-0.000007</td><td>-2.5592e-7</td><td>0.000001</td><td>0.000003</td><td>0.000004</td><td>0.000004</td><td>0.000004</td><td>0.000003</td><td>0.000002</td><td>0.000002</td><td>0.000002</td><td>0.000002</td><td>0.000001</td><td>3.8156e-7</td><td>2.2759e-7</td><td>-1.8720e-7</td><td>-8.5100e-7</td><td>-0.000002</td><td>-0.000002</td><td>-0.000011</td><td>2.692389</td><td>372.740459</td><td>-6.1450e-11</td><td>-1.5388e-9</td><td>0.585838</td><td>2.459735</td><td>1.616068</td><td>1.841222</td></tr><tr><td>&quot;test_99998&quot;</td><td>0.000037</td><td>0.000027</td><td>0.000074</td><td>0.000083</td><td>0.000103</td><td>0.0001</td><td>0.000074</td><td>0.00006</td><td>0.000036</td><td>0.000025</td><td>0.000019</td><td>0.000015</td><td>0.000012</td><td>0.000009</td><td>0.000007</td><td>0.000006</td><td>0.000004</td><td>0.000003</td><td>-0.000004</td><td>0.000002</td><td>8.3415e-7</td><td>-0.000002</td><td>-0.000002</td><td>-0.000002</td><td>-0.000003</td><td>-0.000005</td><td>-0.000005</td><td>-0.000004</td><td>-0.000005</td><td>-0.000006</td><td>-0.000008</td><td>-0.00001</td><td>-0.00001</td><td>-0.00001</td><td>-0.000012</td><td>-0.000012</td><td>&hellip;</td><td>-3.5496e-7</td><td>-2.2363e-7</td><td>-1.2612e-7</td><td>4.9156e-8</td><td>2.2629e-7</td><td>1.6118e-7</td><td>1.1123e-7</td><td>-6.9520e-8</td><td>-3.0026e-7</td><td>-3.2387e-7</td><td>-3.7658e-7</td><td>-3.0529e-7</td><td>-5.0827e-7</td><td>-0.000003</td><td>-0.000006</td><td>-0.000003</td><td>-0.000004</td><td>-0.000005</td><td>6.5025e-8</td><td>0.000002</td><td>0.000002</td><td>0.000002</td><td>0.000008</td><td>0.000011</td><td>0.000029</td><td>0.000007</td><td>-0.000008</td><td>-0.000005</td><td>-0.000012</td><td>140.45613</td><td>324.879708</td><td>-5.9189e-11</td><td>5.0573e-9</td><td>34.861816</td><td>46.74364</td><td>45.663931</td><td>26.174726</td></tr></tbody></table></div>"],"text/plain":["shape: (625_000, 369)\n","\n"," sample_id  ptend_t_0  ptend_t_1  ptend_t_2    cam_out_S  cam_out_S  cam_out_S  cam_out_ \n"," ---        ---        ---        ---           OLS        OLL        OLSD       SOLLD    \n"," str        f64        f64        f64           ---        ---        ---        ---      \n","                                                f64        f64        f64        f64      \n","\n"," test_0     0.000006   -0.000061  -0.000079    0.587271   0.470669   -0.507998  0.400657 \n"," test_10    0.000002   -0.000026  -0.000015    4.560882   2.484528   2.899083   2.119797 \n"," test_100   0.000001   -0.000067  -0.000024    0.430553   0.54001    1.814647   1.376022 \n"," test_1000  0.000027   0.00001    0.000032     -1.907318  5.347664   5.404898   0.65688  \n"," test_1000  0.000048   0.000026   0.000045     443.55831  456.53697  49.490086  4.552832 \n"," 0                                              8          4                              \n","                                                                                 \n"," test_9999  0.000052   -0.000012  0.000019     178.62475  193.12039  68.456994  29.11025 \n"," 4                                              5                                2        \n"," test_9999  0.000006   -0.000059  -0.000136    -0.71373   0.002402   -0.584252  0.280264 \n"," 5                                                                                        \n"," test_9999  0.000031   0.000006   0.000013     106.77063  161.32135  64.524485  20.79693 \n"," 6                                              8          2                     8        \n"," test_9999  -0.000009  -0.000006  -0.00003     0.585838   2.459735   1.616068   1.841222 \n"," 7                                                                                        \n"," test_9999  0.000037   0.000027   0.000074     34.861816  46.74364   45.663931  26.17472 \n"," 8                                                                               6        \n",""]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df_subm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for t in  TARGET_NAMES:\n","    df_subm = df_subm.with_columns(\n","    df_subm[t].clip(y[t].min()*test[t].max(), y[t].max()*test[t].max()).alias(t)\n","    )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (625_000, 369)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sample_id</th><th>ptend_t_0</th><th>ptend_t_1</th><th>ptend_t_2</th><th>ptend_t_3</th><th>ptend_t_4</th><th>ptend_t_5</th><th>ptend_t_6</th><th>ptend_t_7</th><th>ptend_t_8</th><th>ptend_t_9</th><th>ptend_t_10</th><th>ptend_t_11</th><th>ptend_t_12</th><th>ptend_t_13</th><th>ptend_t_14</th><th>ptend_t_15</th><th>ptend_t_16</th><th>ptend_t_17</th><th>ptend_t_18</th><th>ptend_t_19</th><th>ptend_t_20</th><th>ptend_t_21</th><th>ptend_t_22</th><th>ptend_t_23</th><th>ptend_t_24</th><th>ptend_t_25</th><th>ptend_t_26</th><th>ptend_t_27</th><th>ptend_t_28</th><th>ptend_t_29</th><th>ptend_t_30</th><th>ptend_t_31</th><th>ptend_t_32</th><th>ptend_t_33</th><th>ptend_t_34</th><th>ptend_t_35</th><th>&hellip;</th><th>ptend_v_31</th><th>ptend_v_32</th><th>ptend_v_33</th><th>ptend_v_34</th><th>ptend_v_35</th><th>ptend_v_36</th><th>ptend_v_37</th><th>ptend_v_38</th><th>ptend_v_39</th><th>ptend_v_40</th><th>ptend_v_41</th><th>ptend_v_42</th><th>ptend_v_43</th><th>ptend_v_44</th><th>ptend_v_45</th><th>ptend_v_46</th><th>ptend_v_47</th><th>ptend_v_48</th><th>ptend_v_49</th><th>ptend_v_50</th><th>ptend_v_51</th><th>ptend_v_52</th><th>ptend_v_53</th><th>ptend_v_54</th><th>ptend_v_55</th><th>ptend_v_56</th><th>ptend_v_57</th><th>ptend_v_58</th><th>ptend_v_59</th><th>cam_out_NETSW</th><th>cam_out_FLWDS</th><th>cam_out_PRECSC</th><th>cam_out_PRECC</th><th>cam_out_SOLS</th><th>cam_out_SOLL</th><th>cam_out_SOLSD</th><th>cam_out_SOLLD</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;test_0&quot;</td><td>0.000006</td><td>-0.000061</td><td>-0.000079</td><td>-0.000082</td><td>-0.000092</td><td>-0.000094</td><td>-0.000078</td><td>-0.000062</td><td>-0.000047</td><td>-0.000039</td><td>-0.000027</td><td>-0.000017</td><td>-0.000008</td><td>-0.000003</td><td>3.5914e-8</td><td>0.000002</td><td>0.000006</td><td>0.000004</td><td>0.000002</td><td>-0.000006</td><td>0.000007</td><td>-0.000003</td><td>-0.000012</td><td>-0.000016</td><td>-0.000015</td><td>-0.000012</td><td>-0.000015</td><td>-0.000017</td><td>-0.000021</td><td>-0.000028</td><td>-0.000036</td><td>-0.000032</td><td>-0.000023</td><td>-0.000019</td><td>-0.000018</td><td>-0.000016</td><td>&hellip;</td><td>4.1542e-7</td><td>0.000002</td><td>-2.3328e-7</td><td>-0.000002</td><td>-0.000001</td><td>-7.0200e-7</td><td>-6.2644e-7</td><td>-0.000003</td><td>-7.2478e-7</td><td>-5.9234e-7</td><td>3.3608e-8</td><td>-0.000003</td><td>0.000005</td><td>0.000001</td><td>0.000002</td><td>-0.000005</td><td>-0.000008</td><td>-0.000024</td><td>-0.000046</td><td>-0.000045</td><td>-0.000018</td><td>0.000033</td><td>0.000038</td><td>0.000041</td><td>0.000021</td><td>0.000013</td><td>0.000009</td><td>0.000006</td><td>6.1466e-7</td><td>0.0</td><td>397.388142</td><td>3.2604e-11</td><td>0.0</td><td>0.587271</td><td>0.470669</td><td>0.0</td><td>0.400657</td></tr><tr><td>&quot;test_10&quot;</td><td>0.000002</td><td>-0.000026</td><td>-0.000015</td><td>-0.000036</td><td>-0.000078</td><td>-0.00012</td><td>-0.000122</td><td>-0.000085</td><td>-0.000037</td><td>-0.000018</td><td>-0.000013</td><td>-0.000011</td><td>-0.00001</td><td>-0.000008</td><td>-0.000006</td><td>-0.000005</td><td>-0.000004</td><td>-0.000003</td><td>-0.000001</td><td>-0.000005</td><td>-0.000004</td><td>-0.000007</td><td>-0.000007</td><td>-0.000007</td><td>-0.000008</td><td>-0.000011</td><td>-0.000013</td><td>-0.000017</td><td>-0.000018</td><td>-0.00002</td><td>-0.00002</td><td>-0.000016</td><td>-0.000011</td><td>-0.000003</td><td>-4.0443e-7</td><td>0.000002</td><td>&hellip;</td><td>-4.5267e-7</td><td>-4.0156e-7</td><td>3.3495e-7</td><td>4.5810e-7</td><td>3.6472e-7</td><td>2.5676e-7</td><td>2.3085e-7</td><td>1.4759e-7</td><td>-6.4173e-8</td><td>4.4971e-8</td><td>3.7528e-7</td><td>-0.000001</td><td>4.6093e-7</td><td>-4.4998e-7</td><td>0.000002</td><td>3.2108e-7</td><td>-5.2167e-7</td><td>-0.000002</td><td>-0.000002</td><td>-0.000002</td><td>-0.000003</td><td>-0.000001</td><td>1.6279e-7</td><td>0.000001</td><td>0.000003</td><td>0.000002</td><td>0.000001</td><td>-0.000001</td><td>0.000004</td><td>10.601492</td><td>334.870423</td><td>5.7478e-11</td><td>0.0</td><td>4.560882</td><td>2.484528</td><td>2.899083</td><td>2.119797</td></tr><tr><td>&quot;test_100&quot;</td><td>0.000001</td><td>-0.000067</td><td>-0.000024</td><td>-0.000024</td><td>-0.000071</td><td>-0.000093</td><td>-0.000077</td><td>-0.000049</td><td>-0.000028</td><td>-0.000019</td><td>-0.000015</td><td>-0.000013</td><td>-0.000011</td><td>-0.000009</td><td>-0.000006</td><td>-0.000004</td><td>-0.000003</td><td>-0.000004</td><td>0.000004</td><td>-0.000009</td><td>-0.000004</td><td>-0.000007</td><td>-0.000006</td><td>-0.000006</td><td>-0.000004</td><td>-0.000004</td><td>-0.000007</td><td>-0.000005</td><td>-0.000006</td><td>-0.000011</td><td>-0.000014</td><td>-0.000017</td><td>-0.00002</td><td>-0.00002</td><td>-0.000023</td><td>-0.000024</td><td>&hellip;</td><td>-0.000002</td><td>-0.000002</td><td>-7.7685e-7</td><td>3.2854e-7</td><td>8.2988e-7</td><td>4.8305e-7</td><td>4.3648e-7</td><td>5.4116e-7</td><td>3.1635e-7</td><td>8.8304e-8</td><td>-2.9214e-7</td><td>-2.8616e-7</td><td>3.4695e-8</td><td>0.000002</td><td>8.7396e-7</td><td>-3.6196e-7</td><td>-0.000002</td><td>-0.000005</td><td>-0.00001</td><td>-0.00002</td><td>-0.000023</td><td>0.000008</td><td>0.00001</td><td>0.000013</td><td>0.000009</td><td>0.000002</td><td>0.000004</td><td>0.000003</td><td>0.000012</td><td>8.011045</td><td>327.582036</td><td>1.8015e-11</td><td>4.4917e-9</td><td>0.430553</td><td>0.54001</td><td>1.814647</td><td>1.376022</td></tr><tr><td>&quot;test_1000&quot;</td><td>0.000027</td><td>0.00001</td><td>0.000032</td><td>0.000028</td><td>-0.000008</td><td>-0.000052</td><td>-0.000044</td><td>-0.000021</td><td>-0.000006</td><td>-0.000002</td><td>-3.4139e-7</td><td>2.1442e-9</td><td>0.000001</td><td>0.000003</td><td>0.000004</td><td>0.000005</td><td>0.000006</td><td>0.000005</td><td>5.3782e-7</td><td>6.5935e-7</td><td>-1.2208e-7</td><td>-0.000001</td><td>-0.000009</td><td>-0.000018</td><td>-0.000016</td><td>-0.000013</td><td>-0.000015</td><td>-0.000017</td><td>-0.000021</td><td>-0.000023</td><td>-0.000021</td><td>-0.000021</td><td>-0.000018</td><td>-0.000017</td><td>-0.000016</td><td>-0.000016</td><td>&hellip;</td><td>1.6961e-9</td><td>-3.6256e-8</td><td>7.2284e-7</td><td>-0.000001</td><td>-2.6620e-8</td><td>0.000002</td><td>-0.000002</td><td>2.4478e-7</td><td>-9.7982e-7</td><td>4.2177e-7</td><td>-0.000003</td><td>0.000006</td><td>0.000003</td><td>0.000005</td><td>0.00001</td><td>0.000009</td><td>0.000008</td><td>0.00001</td><td>0.000008</td><td>0.000006</td><td>0.000006</td><td>0.000004</td><td>3.7408e-7</td><td>-0.000008</td><td>-0.000013</td><td>-0.000023</td><td>-0.000038</td><td>-0.000046</td><td>0.000027</td><td>4.040341</td><td>357.350264</td><td>3.5015e-11</td><td>2.0998e-9</td><td>0.0</td><td>5.347664</td><td>5.404898</td><td>0.65688</td></tr><tr><td>&quot;test_10000&quot;</td><td>0.000048</td><td>0.000026</td><td>0.000045</td><td>0.000085</td><td>0.000124</td><td>0.000174</td><td>0.000189</td><td>0.000147</td><td>0.000088</td><td>0.000062</td><td>0.000044</td><td>0.000035</td><td>0.000028</td><td>0.000019</td><td>0.000014</td><td>0.000011</td><td>0.000011</td><td>0.00001</td><td>0.000008</td><td>0.000006</td><td>0.000003</td><td>7.5474e-8</td><td>-0.000003</td><td>-0.000006</td><td>-0.00001</td><td>-0.000012</td><td>-0.000007</td><td>-0.000005</td><td>-0.000004</td><td>-0.000003</td><td>-0.000003</td><td>-0.000004</td><td>-0.000006</td><td>-0.000005</td><td>0.000002</td><td>3.5198e-7</td><td>&hellip;</td><td>4.7352e-8</td><td>7.6939e-8</td><td>1.0423e-7</td><td>7.4223e-8</td><td>1.3454e-8</td><td>4.8909e-8</td><td>2.7731e-8</td><td>-5.7962e-8</td><td>-1.9916e-7</td><td>1.0272e-7</td><td>-1.1223e-7</td><td>-5.3022e-8</td><td>-1.1611e-7</td><td>-2.2008e-7</td><td>2.3183e-7</td><td>-4.0258e-8</td><td>-2.7363e-7</td><td>1.6265e-7</td><td>5.3130e-8</td><td>-1.5505e-7</td><td>1.8466e-7</td><td>2.6863e-7</td><td>-4.9842e-7</td><td>-0.000001</td><td>2.1940e-7</td><td>0.000001</td><td>-1.7046e-7</td><td>6.4940e-7</td><td>-0.000002</td><td>926.089563</td><td>372.916137</td><td>6.3593e-11</td><td>0.0</td><td>443.558318</td><td>456.536974</td><td>49.490086</td><td>4.552832</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;test_99994&quot;</td><td>0.000052</td><td>-0.000012</td><td>0.000019</td><td>0.000098</td><td>0.000126</td><td>0.00016</td><td>0.000142</td><td>0.000105</td><td>0.000066</td><td>0.000048</td><td>0.000038</td><td>0.000032</td><td>0.000024</td><td>0.000018</td><td>0.000011</td><td>0.000009</td><td>0.000009</td><td>0.000004</td><td>0.000002</td><td>0.000006</td><td>0.000007</td><td>-0.000001</td><td>-0.000005</td><td>-0.000001</td><td>-0.000002</td><td>-0.000003</td><td>-0.000009</td><td>-0.000021</td><td>-0.00002</td><td>-0.000018</td><td>-0.000016</td><td>-0.000014</td><td>-0.000009</td><td>-0.000002</td><td>-0.000013</td><td>-0.000008</td><td>&hellip;</td><td>0.000011</td><td>-0.000011</td><td>-0.000012</td><td>-0.00002</td><td>-0.000005</td><td>-0.000002</td><td>-0.000005</td><td>-0.000011</td><td>-0.000018</td><td>-0.00002</td><td>-0.000018</td><td>-0.000013</td><td>-0.000014</td><td>-0.000019</td><td>-0.000024</td><td>-0.000017</td><td>0.000004</td><td>0.00001</td><td>0.000014</td><td>0.000048</td><td>0.000052</td><td>0.000045</td><td>0.000038</td><td>0.000027</td><td>0.000015</td><td>0.000005</td><td>0.000002</td><td>0.000002</td><td>0.000006</td><td>427.249057</td><td>396.851407</td><td>4.4519e-13</td><td>3.7356e-8</td><td>178.624755</td><td>193.12039</td><td>68.456994</td><td>29.110252</td></tr><tr><td>&quot;test_99995&quot;</td><td>0.000006</td><td>-0.000059</td><td>-0.000136</td><td>-0.000075</td><td>-0.000065</td><td>-0.000062</td><td>-0.000051</td><td>-0.000041</td><td>-0.000026</td><td>-0.000018</td><td>-0.000012</td><td>-0.000009</td><td>-0.000008</td><td>-0.000008</td><td>-0.000008</td><td>-0.000007</td><td>-0.000007</td><td>-0.000007</td><td>-0.000006</td><td>-0.000006</td><td>-0.000005</td><td>-0.000004</td><td>-0.000004</td><td>-0.000004</td><td>-0.000004</td><td>-0.000004</td><td>-0.000004</td><td>-0.000005</td><td>-0.000006</td><td>-0.000006</td><td>-0.000006</td><td>-0.000007</td><td>-0.000007</td><td>-0.000007</td><td>-0.000008</td><td>-0.000009</td><td>&hellip;</td><td>-3.5795e-8</td><td>7.2994e-9</td><td>2.3149e-8</td><td>2.5757e-8</td><td>4.6870e-8</td><td>2.6178e-8</td><td>5.6546e-8</td><td>-6.5036e-10</td><td>2.3678e-9</td><td>-1.9364e-8</td><td>-9.7366e-9</td><td>6.6870e-8</td><td>9.3123e-8</td><td>2.4060e-8</td><td>-3.3708e-8</td><td>3.7794e-8</td><td>1.3103e-7</td><td>-6.4873e-8</td><td>-1.7315e-7</td><td>-8.2143e-8</td><td>2.3283e-7</td><td>2.0321e-8</td><td>1.2850e-7</td><td>1.9731e-7</td><td>-8.5721e-8</td><td>0.000002</td><td>-0.000001</td><td>0.000003</td><td>-0.000004</td><td>0.0</td><td>128.122883</td><td>2.5634e-9</td><td>3.2854e-9</td><td>0.0</td><td>0.002402</td><td>0.0</td><td>0.280264</td></tr><tr><td>&quot;test_99996&quot;</td><td>0.000031</td><td>0.000006</td><td>0.000013</td><td>0.000021</td><td>0.000039</td><td>0.00006</td><td>0.000056</td><td>0.000042</td><td>0.000024</td><td>0.000016</td><td>0.000011</td><td>0.000007</td><td>0.000005</td><td>0.000005</td><td>0.000005</td><td>0.000005</td><td>0.000003</td><td>0.000002</td><td>0.000003</td><td>0.000001</td><td>2.2346e-7</td><td>3.0421e-7</td><td>-5.3960e-7</td><td>-9.6354e-7</td><td>-3.7817e-7</td><td>-4.0651e-7</td><td>4.1853e-7</td><td>-2.9684e-7</td><td>-0.000001</td><td>-0.000001</td><td>-0.000001</td><td>-0.000001</td><td>-0.000002</td><td>-0.000002</td><td>-0.000003</td><td>-0.000004</td><td>&hellip;</td><td>-2.0458e-8</td><td>3.1802e-9</td><td>3.7653e-8</td><td>6.8424e-8</td><td>6.3794e-8</td><td>4.7582e-8</td><td>1.9864e-8</td><td>-9.7067e-9</td><td>-1.8813e-8</td><td>-3.1179e-8</td><td>-1.0820e-7</td><td>-7.1723e-8</td><td>1.3050e-7</td><td>5.7256e-8</td><td>2.3133e-7</td><td>3.5186e-8</td><td>8.9988e-8</td><td>3.6928e-8</td><td>-2.0055e-8</td><td>-5.8986e-8</td><td>-9.0440e-8</td><td>-1.0623e-7</td><td>1.8405e-8</td><td>3.3700e-8</td><td>-6.1914e-8</td><td>8.0526e-8</td><td>-3.9113e-8</td><td>-6.1224e-7</td><td>-1.9768e-7</td><td>76.277159</td><td>182.980684</td><td>6.4787e-9</td><td>6.1867e-9</td><td>106.770638</td><td>161.321352</td><td>64.524485</td><td>20.796938</td></tr><tr><td>&quot;test_99997&quot;</td><td>-0.000009</td><td>-0.000006</td><td>-0.00003</td><td>-0.000051</td><td>-0.000079</td><td>-0.000109</td><td>-0.000096</td><td>-0.000067</td><td>-0.000043</td><td>-0.000036</td><td>-0.000028</td><td>-0.00002</td><td>-0.000013</td><td>-0.000009</td><td>-0.000002</td><td>0.000001</td><td>0.000004</td><td>0.000004</td><td>0.000001</td><td>4.6972e-7</td><td>-0.000005</td><td>-0.000007</td><td>-0.000009</td><td>-0.000015</td><td>-0.000018</td><td>-0.000023</td><td>-0.00003</td><td>-0.00003</td><td>-0.000027</td><td>-0.000024</td><td>-0.000025</td><td>-0.000025</td><td>-0.000024</td><td>-0.000026</td><td>-0.000027</td><td>-0.000027</td><td>&hellip;</td><td>-3.4754e-7</td><td>-9.9077e-7</td><td>-0.000001</td><td>-7.9622e-7</td><td>-1.5085e-7</td><td>-1.1935e-7</td><td>2.7211e-7</td><td>0.000004</td><td>-0.000007</td><td>-0.000007</td><td>-2.5592e-7</td><td>0.000001</td><td>0.000003</td><td>0.000004</td><td>0.000004</td><td>0.000004</td><td>0.000003</td><td>0.000002</td><td>0.000002</td><td>0.000002</td><td>0.000002</td><td>0.000001</td><td>3.8156e-7</td><td>2.2759e-7</td><td>-1.8720e-7</td><td>-8.5100e-7</td><td>-0.000002</td><td>-0.000002</td><td>-0.000011</td><td>2.692389</td><td>372.740459</td><td>0.0</td><td>0.0</td><td>0.585838</td><td>2.459735</td><td>1.616068</td><td>1.841222</td></tr><tr><td>&quot;test_99998&quot;</td><td>0.000037</td><td>0.000027</td><td>0.000074</td><td>0.000083</td><td>0.000103</td><td>0.0001</td><td>0.000074</td><td>0.00006</td><td>0.000036</td><td>0.000025</td><td>0.000019</td><td>0.000015</td><td>0.000012</td><td>0.000009</td><td>0.000007</td><td>0.000006</td><td>0.000004</td><td>0.000003</td><td>-0.000004</td><td>0.000002</td><td>8.3415e-7</td><td>-0.000002</td><td>-0.000002</td><td>-0.000002</td><td>-0.000003</td><td>-0.000005</td><td>-0.000005</td><td>-0.000004</td><td>-0.000005</td><td>-0.000006</td><td>-0.000008</td><td>-0.00001</td><td>-0.00001</td><td>-0.00001</td><td>-0.000012</td><td>-0.000012</td><td>&hellip;</td><td>-3.5496e-7</td><td>-2.2363e-7</td><td>-1.2612e-7</td><td>4.9156e-8</td><td>2.2629e-7</td><td>1.6118e-7</td><td>1.1123e-7</td><td>-6.9520e-8</td><td>-3.0026e-7</td><td>-3.2387e-7</td><td>-3.7658e-7</td><td>-3.0529e-7</td><td>-5.0827e-7</td><td>-0.000003</td><td>-0.000006</td><td>-0.000003</td><td>-0.000004</td><td>-0.000005</td><td>6.5025e-8</td><td>0.000002</td><td>0.000002</td><td>0.000002</td><td>0.000008</td><td>0.000011</td><td>0.000029</td><td>0.000007</td><td>-0.000008</td><td>-0.000005</td><td>-0.000012</td><td>140.45613</td><td>324.879708</td><td>0.0</td><td>5.0573e-9</td><td>34.861816</td><td>46.74364</td><td>45.663931</td><td>26.174726</td></tr></tbody></table></div>"],"text/plain":["shape: (625_000, 369)\n","\n"," sample_id  ptend_t_0  ptend_t_1  ptend_t_2    cam_out_S  cam_out_S  cam_out_S  cam_out_ \n"," ---        ---        ---        ---           OLS        OLL        OLSD       SOLLD    \n"," str        f64        f64        f64           ---        ---        ---        ---      \n","                                                f64        f64        f64        f64      \n","\n"," test_0     0.000006   -0.000061  -0.000079    0.587271   0.470669   0.0        0.400657 \n"," test_10    0.000002   -0.000026  -0.000015    4.560882   2.484528   2.899083   2.119797 \n"," test_100   0.000001   -0.000067  -0.000024    0.430553   0.54001    1.814647   1.376022 \n"," test_1000  0.000027   0.00001    0.000032     0.0        5.347664   5.404898   0.65688  \n"," test_1000  0.000048   0.000026   0.000045     443.55831  456.53697  49.490086  4.552832 \n"," 0                                              8          4                              \n","                                                                                 \n"," test_9999  0.000052   -0.000012  0.000019     178.62475  193.12039  68.456994  29.11025 \n"," 4                                              5                                2        \n"," test_9999  0.000006   -0.000059  -0.000136    0.0        0.002402   0.0        0.280264 \n"," 5                                                                                        \n"," test_9999  0.000031   0.000006   0.000013     106.77063  161.32135  64.524485  20.79693 \n"," 6                                              8          2                     8        \n"," test_9999  -0.000009  -0.000006  -0.00003     0.585838   2.459735   1.616068   1.841222 \n"," 7                                                                                        \n"," test_9999  0.000037   0.000027   0.000074     34.861816  46.74364   45.663931  26.17472 \n"," 8                                                                               6        \n",""]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df_subm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_subm.write_csv(\"submission.csv\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8015876,"sourceId":56537,"sourceType":"competition"},{"datasetId":4998928,"sourceId":8404301,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"}},"nbformat":4,"nbformat_minor":4}
